{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'AMOUNT_OF_LFS': 2.0,\n 'DATASET': 'HEART',\n 'DATASET_RANDOM_GENERATION_SEED': 28296.0,\n 'FRACTION_OF_INITIALLY_LABELLED_SAMPLES': 0.3742707957561203,\n 'FRACTION_OF_LASTLY_AL_LABELLED_SAMPLES': 0.3706421470668909,\n 'JOB_ID': 75.0,\n 'LF_RANDOM_SEED': 238068.0,\n 'MERGE_WS_SAMPLES_STRATEGY': 'MajorityVoteLabelMergeStrategy',\n 'acc_al_and_al': 0.3708609271523179,\n 'acc_al_and_ws_and_al': 0.8874172185430463,\n 'acc_initial': 0.3973509933774834,\n 'acc_ws': 0.9867549668874172,\n 'al_sampling_strategy': 'UncertaintyMaxMargin_no_ws',\n 'amount_of_initial_al_samples': 57.0,\n 'amount_of_lastly_al_samples': 35.0,\n 'class_sep': '?',\n 'f1_al_and_al': 0.5410628019323671,\n 'f1_al_and_ws_and_al': 0.9403508771929824,\n 'f1_initial': 0.5687203791469194,\n 'f1_ws': 0.9933333333333334,\n 'flip_y': '?',\n 'hypercube': '?',\n 'n_classes': 2.0,\n 'n_clusters_per_class': '?',\n 'n_features': 14.0,\n 'n_informative': 14.0,\n 'n_redundant': 0.0,\n 'n_repeated': 0.0,\n 'n_samples': 303.0,\n 'random_state': 28296.0,\n 'scale': '?',\n 'weights': '?',\n 'ABSTAIN_THRESHOLDS_0.0': 1,\n 'ABSTAIN_THRESHOLDS_0.9': 1,\n 'ABSTAIN_THRESHOLDS_0.5': 0,\n 'ABSTAIN_THRESHOLDS_0.4': 0,\n 'ABSTAIN_THRESHOLDS_0.1': 0,\n 'ABSTAIN_THRESHOLDS_0.2': 0,\n 'ABSTAIN_THRESHOLDS_1.0': 0,\n 'ABSTAIN_THRESHOLDS_0.7': 0,\n 'ABSTAIN_THRESHOLDS_0.6': 0,\n 'ABSTAIN_THRESHOLDS_0.3': 0,\n 'ABSTAIN_THRESHOLDS_0.8': 0,\n 'AL_SAMPLES_WEIGHT_30': 1,\n 'AL_SAMPLES_WEIGHT_10': 0,\n 'AL_SAMPLES_WEIGHT_50': 0,\n 'AL_SAMPLES_WEIGHT_40': 0,\n 'AL_SAMPLES_WEIGHT_70': 0,\n 'AL_SAMPLES_WEIGHT_0': 0,\n 'AL_SAMPLES_WEIGHT_80': 0,\n 'AL_SAMPLES_WEIGHT_90': 0,\n 'AL_SAMPLES_WEIGHT_60': 0,\n 'AL_SAMPLES_WEIGHT_100': 0,\n 'AL_SAMPLES_WEIGHT_20': 0,\n 'LF_CLASSIFIERS_knn': 1,\n 'LF_CLASSIFIERS_dt': 1,\n 'LF_CLASSIFIERS_lr': 0,\n 'AMOUNT_OF_LF_FEATURESSS_1': 2,\n 'AMOUNT_OF_LF_FEATURESSS_2': 0,\n 'AMOUNT_OF_LF_FEATURESSS_5': 0,\n 'AMOUNT_OF_LF_FEATURESSS_3': 0,\n 'AMOUNT_OF_LF_FEATURESSS_4': 0}"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from active_learning.learner.standard import Learner, get_classifier\n",
    "from active_learning.weak_supervision.SelfTraining import SelfTraining\n",
    "import argparse\n",
    "import numpy as np\n",
    "import copy\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from timeit import default_timer as timer\n",
    "from typing import List, Dict\n",
    "from active_learning.config import get_active_config\n",
    "from active_learning.dataStorage import DataStorage\n",
    "from active_learning.datasets import load_synthetic\n",
    "from active_learning.logger import init_logger\n",
    "from active_learning.merge_weak_supervision_label_strategies.MajorityVoteLabelMergeStrategy import (\n",
    "    MajorityVoteLabelMergeStrategy,\n",
    ")\n",
    "from collections import Counter\n",
    "\n",
    "from active_learning.weak_supervision import SyntheticLabelingFunctions\n",
    "from active_learning.weak_supervision.BaseWeakSupervision import BaseWeakSupervision\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "\n",
    "font_size = 8\n",
    "\n",
    "tex_fonts = {\n",
    "    # Use LaTeX to write all text\n",
    "    # \"text.usetex\": True,\n",
    "    \"text.usetex\": False,\n",
    "    \"font.family\": [\"Times New Roman\", 'sans-serif'],\n",
    "    # Use 10pt font in plots, to match 10pt font in document\n",
    "    \"axes.labelsize\": font_size,\n",
    "    \"font.size\": font_size,\n",
    "    # Make the legend/label fonts a little smaller\n",
    "    \"legend.fontsize\": font_size,\n",
    "    \"xtick.labelsize\": font_size,\n",
    "    \"ytick.labelsize\": font_size,\n",
    "    \"xtick.bottom\": True,\n",
    "    \"figure.autolayout\": True,\n",
    "}\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\")\n",
    "plt.rcParams.update(tex_fonts)  # type: ignore\n",
    "\n",
    "\n",
    "# https://jwalton.info/Embed-Publication-Matplotlib-Latex/\n",
    "def set_matplotlib_size(width, fraction=1):\n",
    "    \"\"\"Set figure dimensions to avoid scaling in LaTeX.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    width: float\n",
    "            Document textwidth or columnwidth in pts\n",
    "    fraction: float, optional\n",
    "            Fraction of the width which you wish the figure to occupy\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fig_dim: tuple\n",
    "            Dimensions of figure in inches\n",
    "    \"\"\"\n",
    "    # Width of figure (in pts)\n",
    "    fig_width_pt = width * fraction\n",
    "\n",
    "    # Convert from pt to inches\n",
    "    inches_per_pt = 1 / 72.27\n",
    "\n",
    "    # Golden ratio to set aesthetic figure height\n",
    "    # https://disq.us/p/2940ij3\n",
    "    golden_ratio = (5 ** 0.5 - 1) / 2\n",
    "\n",
    "    # Figure width in inches\n",
    "    fig_width_in = fig_width_pt * inches_per_pt\n",
    "    # Figure height in inches\n",
    "    fig_height_in = fig_width_in * golden_ratio\n",
    "\n",
    "    fig_dim = (fig_width_in, fig_height_in)\n",
    "\n",
    "    return fig_dim\n",
    "\n",
    "\n",
    "#width = 505.89\n",
    "width = 1500\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"new.csv\")\n",
    "df['AMOUNT_OF_LFS'] = np.ceil(df['AMOUNT_OF_LFS'])\n",
    "df.iloc[0].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desirable Output: \"exps with al_ws_al > ws_al\": \n",
    "    lf_classifiers_knn:     80% vs 40% (all)\n",
    "    amount_of_lf_features:  4.5 vs 7.0\n",
    "    Offene Frage: macht es Sinn den Vergleich gegen ALL zu machen, oder lieber vergleich gegen \"not davor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56034\n",
      "Accuracy after AL, WS, AL is greater than after AL and WS\n"
     ]
    },
    {
     "data": {
      "text/html": "<table>\n<tbody>\n<tr><td>Amount                                </td><td>29935                                                                                                                                                                 </td><td>         </td><td>26099                                                                                                                                                              </td><td>          </td></tr>\n<tr><td>AMOUNT_OF_LFS                         </td><td>4.7                                                                                                                                                                   </td><td>±2.74%   </td><td>4.8                                                                                                                                                                </td><td>±3.00%    </td></tr>\n<tr><td>DATASET                               </td><td>synthetic: 15350 | cifar10: 1506 | flag: 1274 | australian: 1146 | DIABETES: 1065                                                                                     </td><td>         </td><td>synthetic: 3238,HEART: 1703,FERTILITY: 1686,PLANNING: 1339,abalone: 1331                                                                                           </td><td>          </td></tr>\n<tr><td>FRACTION_OF_INITIALLY_LABELLED_SAMPLES</td><td>0.48                                                                                                                                                                  </td><td>±0.31%   </td><td>0.5                                                                                                                                                                </td><td>±0.35%    </td></tr>\n<tr><td>FRACTION_OF_LASTLY_AL_LABELLED_SAMPLES</td><td>0.54                                                                                                                                                                  </td><td>±0.31%   </td><td>0.46                                                                                                                                                               </td><td>±0.36%    </td></tr>\n<tr><td>MERGE_WS_SAMPLES_STRATEGY             </td><td>RandomLabelMergeStrategy: 11205 | MajorityVoteLabelMergeStrategy: 10264 | SnorkelLabelMergeStrategy: 8466                                                             </td><td>         </td><td>MajorityVoteLabelMergeStrategy: 10274,RandomLabelMergeStrategy: 9699,SnorkelLabelMergeStrategy: 6126                                                               </td><td>          </td></tr>\n<tr><td>acc_al_and_al                         </td><td>0.6                                                                                                                                                                   </td><td>±0.20%   </td><td>0.56                                                                                                                                                               </td><td>±0.33%    </td></tr>\n<tr><td>acc_al_and_ws_and_al                  </td><td>0.58                                                                                                                                                                  </td><td>±0.20%   </td><td>0.56                                                                                                                                                               </td><td>±0.31%    </td></tr>\n<tr><td>acc_initial                           </td><td>0.58                                                                                                                                                                  </td><td>±0.20%   </td><td>0.58                                                                                                                                                               </td><td>±0.32%    </td></tr>\n<tr><td>acc_ws                                </td><td>0.53                                                                                                                                                                  </td><td>±0.20%   </td><td>0.59                                                                                                                                                               </td><td>±0.31%    </td></tr>\n<tr><td>al_sampling_strategy                  </td><td>Random: 5235 | CoveredByLeastAmountOfLf: 5132 | UncertaintyMaxMargin_no_ws: 5053 | UncertaintyMaxMargin_with_ws: 5053 | GreatestDisagreement: 4878                    </td><td>         </td><td>ClassificationIsMostWrong: 4755,GreatestDisagreement: 4461,UncertaintyMaxMargin_no_ws: 4286,UncertaintyMaxMargin_with_ws: 4286,CoveredByLeastAmountOfLf: 4207      </td><td>          </td></tr>\n<tr><td>amount_of_initial_al_samples          </td><td>8.1e+02                                                                                                                                                               </td><td>±2496.96%</td><td>8.1e+02                                                                                                                                                            </td><td>±3381.45% </td></tr>\n<tr><td>amount_of_lastly_al_samples           </td><td>4.2e+02                                                                                                                                                               </td><td>±1389.82%</td><td>4.1e+02                                                                                                                                                            </td><td>±2191.22% </td></tr>\n<tr><td>class_sep                             </td><td>2.1629113779317177: 15350 | ?: 14585                                                                                                                                  </td><td>         </td><td>?: 22861,2.1629113779317177: 3238                                                                                                                                  </td><td>          </td></tr>\n<tr><td>f1_al_and_al                          </td><td>0.55                                                                                                                                                                  </td><td>±0.21%   </td><td>0.54                                                                                                                                                               </td><td>±0.32%    </td></tr>\n<tr><td>f1_al_and_ws_and_al                   </td><td>0.52                                                                                                                                                                  </td><td>±0.23%   </td><td>0.53                                                                                                                                                               </td><td>±0.33%    </td></tr>\n<tr><td>f1_initial                            </td><td>0.53                                                                                                                                                                  </td><td>±0.22%   </td><td>0.56                                                                                                                                                               </td><td>±0.32%    </td></tr>\n<tr><td>f1_ws                                 </td><td>0.47                                                                                                                                                                  </td><td>±0.23%   </td><td>0.55                                                                                                                                                               </td><td>±0.34%    </td></tr>\n<tr><td>flip_y                                </td><td>0.014139337972832518: 15350 | ?: 14585                                                                                                                                </td><td>         </td><td>?: 22861,0.014139337972832518: 3238                                                                                                                                </td><td>          </td></tr>\n<tr><td>hypercube                             </td><td>False: 15350 | ?: 14585                                                                                                                                               </td><td>         </td><td>?: 22861,False: 3238                                                                                                                                               </td><td>          </td></tr>\n<tr><td>n_classes                             </td><td>6.2                                                                                                                                                                   </td><td>±5.19%   </td><td>6.2                                                                                                                                                                </td><td>±10.94%   </td></tr>\n<tr><td>n_clusters_per_class                  </td><td>2: 15350 | ?: 14585                                                                                                                                                   </td><td>         </td><td>?: 22861,2: 3238                                                                                                                                                   </td><td>          </td></tr>\n<tr><td>n_features                            </td><td>2.3e+02                                                                                                                                                               </td><td>±842.75% </td><td>2.4e+02                                                                                                                                                            </td><td>±1040.99% </td></tr>\n<tr><td>n_informative                         </td><td>2.2e+02                                                                                                                                                               </td><td>±845.97% </td><td>2.3e+02                                                                                                                                                            </td><td>±1041.77% </td></tr>\n<tr><td>n_redundant                           </td><td>8.7                                                                                                                                                                   </td><td>±9.63%   </td><td>2.1                                                                                                                                                                </td><td>±6.80%    </td></tr>\n<tr><td>n_repeated                            </td><td>2.6                                                                                                                                                                   </td><td>±2.83%   </td><td>0.62                                                                                                                                                               </td><td>±2.00%    </td></tr>\n<tr><td>n_samples                             </td><td>3.3e+03                                                                                                                                                               </td><td>±8600.81%</td><td>3.2e+03                                                                                                                                                            </td><td>±11712.35%</td></tr>\n<tr><td>scale                                 </td><td>0.01: 15350 | ?: 14585                                                                                                                                                </td><td>         </td><td>?: 22861,0.01: 3238                                                                                                                                                </td><td>          </td></tr>\n<tr><td>weights                               </td><td>[0.06775667270454466, 0.30890863849777156, 0.007983477918928901, 0.022832889838942067, 0.3774195345677848, 0.10398455550059044, 0.11111423097143755]: 15350 | ?: 14585</td><td>         </td><td>?: 22861,[0.06775667270454466, 0.30890863849777156, 0.007983477918928901, 0.022832889838942067, 0.3774195345677848, 0.10398455550059044, 0.11111423097143755]: 3238</td><td>          </td></tr>\n<tr><td>ABSTAIN_THRESHOLDS_0.0                </td><td>0.23                                                                                                                                                                  </td><td>±0.55%   </td><td>0.24                                                                                                                                                               </td><td>±0.60%    </td></tr>\n<tr><td>ABSTAIN_THRESHOLDS_0.9                </td><td>0.48                                                                                                                                                                  </td><td>±0.80%   </td><td>0.48                                                                                                                                                               </td><td>±0.85%    </td></tr>\n<tr><td>ABSTAIN_THRESHOLDS_0.5                </td><td>0.47                                                                                                                                                                  </td><td>±0.78%   </td><td>0.47                                                                                                                                                               </td><td>±0.84%    </td></tr>\n<tr><td>ABSTAIN_THRESHOLDS_0.4                </td><td>0.48                                                                                                                                                                  </td><td>±0.80%   </td><td>0.47                                                                                                                                                               </td><td>±0.85%    </td></tr>\n<tr><td>ABSTAIN_THRESHOLDS_0.1                </td><td>0.46                                                                                                                                                                  </td><td>±0.78%   </td><td>0.48                                                                                                                                                               </td><td>±0.85%    </td></tr>\n<tr><td>ABSTAIN_THRESHOLDS_0.2                </td><td>0.48                                                                                                                                                                  </td><td>±0.79%   </td><td>0.48                                                                                                                                                               </td><td>±0.86%    </td></tr>\n<tr><td>ABSTAIN_THRESHOLDS_1.0                </td><td>0.24                                                                                                                                                                  </td><td>±0.55%   </td><td>0.25                                                                                                                                                               </td><td>±0.62%    </td></tr>\n<tr><td>ABSTAIN_THRESHOLDS_0.7                </td><td>0.48                                                                                                                                                                  </td><td>±0.79%   </td><td>0.47                                                                                                                                                               </td><td>±0.84%    </td></tr>\n<tr><td>ABSTAIN_THRESHOLDS_0.6                </td><td>0.47                                                                                                                                                                  </td><td>±0.79%   </td><td>0.48                                                                                                                                                               </td><td>±0.84%    </td></tr>\n<tr><td>ABSTAIN_THRESHOLDS_0.3                </td><td>0.47                                                                                                                                                                  </td><td>±0.79%   </td><td>0.47                                                                                                                                                               </td><td>±0.85%    </td></tr>\n<tr><td>ABSTAIN_THRESHOLDS_0.8                </td><td>0.46                                                                                                                                                                  </td><td>±0.78%   </td><td>0.47                                                                                                                                                               </td><td>±0.85%    </td></tr>\n<tr><td>AL_SAMPLES_WEIGHT_30                  </td><td>0.092                                                                                                                                                                 </td><td>±0.33%   </td><td>0.091                                                                                                                                                              </td><td>±0.35%    </td></tr>\n<tr><td>AL_SAMPLES_WEIGHT_10                  </td><td>0.086                                                                                                                                                                 </td><td>±0.32%   </td><td>0.081                                                                                                                                                              </td><td>±0.33%    </td></tr>\n<tr><td>AL_SAMPLES_WEIGHT_50                  </td><td>0.092                                                                                                                                                                 </td><td>±0.33%   </td><td>0.089                                                                                                                                                              </td><td>±0.35%    </td></tr>\n<tr><td>AL_SAMPLES_WEIGHT_40                  </td><td>0.11                                                                                                                                                                  </td><td>±0.36%   </td><td>0.11                                                                                                                                                               </td><td>±0.38%    </td></tr>\n<tr><td>AL_SAMPLES_WEIGHT_70                  </td><td>0.09                                                                                                                                                                  </td><td>±0.32%   </td><td>0.088                                                                                                                                                              </td><td>±0.34%    </td></tr>\n<tr><td>AL_SAMPLES_WEIGHT_0                   </td><td>0.056                                                                                                                                                                 </td><td>±0.26%   </td><td>0.057                                                                                                                                                              </td><td>±0.28%    </td></tr>\n<tr><td>AL_SAMPLES_WEIGHT_80                  </td><td>0.11                                                                                                                                                                  </td><td>±0.36%   </td><td>0.11                                                                                                                                                               </td><td>±0.39%    </td></tr>\n<tr><td>AL_SAMPLES_WEIGHT_90                  </td><td>0.084                                                                                                                                                                 </td><td>±0.31%   </td><td>0.092                                                                                                                                                              </td><td>±0.35%    </td></tr>\n<tr><td>AL_SAMPLES_WEIGHT_60                  </td><td>0.11                                                                                                                                                                  </td><td>±0.35%   </td><td>0.11                                                                                                                                                               </td><td>±0.37%    </td></tr>\n<tr><td>AL_SAMPLES_WEIGHT_100                 </td><td>0.052                                                                                                                                                                 </td><td>±0.25%   </td><td>0.05                                                                                                                                                               </td><td>±0.27%    </td></tr>\n<tr><td>AL_SAMPLES_WEIGHT_20                  </td><td>0.12                                                                                                                                                                  </td><td>±0.36%   </td><td>0.12                                                                                                                                                               </td><td>±0.40%    </td></tr>\n<tr><td>LF_CLASSIFIERS_knn                    </td><td>1.6                                                                                                                                                                   </td><td>±1.47%   </td><td>1.5                                                                                                                                                                </td><td>±1.61%    </td></tr>\n<tr><td>LF_CLASSIFIERS_dt                     </td><td>1.6                                                                                                                                                                   </td><td>±1.47%   </td><td>1.6                                                                                                                                                                </td><td>±1.59%    </td></tr>\n<tr><td>LF_CLASSIFIERS_lr                     </td><td>1.5                                                                                                                                                                   </td><td>±1.46%   </td><td>1.6                                                                                                                                                                </td><td>±1.61%    </td></tr>\n<tr><td>AMOUNT_OF_LF_FEATURESSS_1             </td><td>2.9                                                                                                                                                                   </td><td>±2.07%   </td><td>2.9                                                                                                                                                                </td><td>±2.27%    </td></tr>\n<tr><td>AMOUNT_OF_LF_FEATURESSS_2             </td><td>0.83                                                                                                                                                                  </td><td>±1.04%   </td><td>0.82                                                                                                                                                               </td><td>±1.13%    </td></tr>\n<tr><td>AMOUNT_OF_LF_FEATURESSS_5             </td><td>0.24                                                                                                                                                                  </td><td>±0.57%   </td><td>0.25                                                                                                                                                               </td><td>±0.62%    </td></tr>\n<tr><td>AMOUNT_OF_LF_FEATURESSS_3             </td><td>0.47                                                                                                                                                                  </td><td>±0.80%   </td><td>0.48                                                                                                                                                               </td><td>±0.86%    </td></tr>\n<tr><td>AMOUNT_OF_LF_FEATURESSS_4             </td><td>0.33                                                                                                                                                                  </td><td>±0.66%   </td><td>0.32                                                                                                                                                               </td><td>±0.70%    </td></tr>\n</tbody>\n</table>",
      "text/plain": "'<table>\\n<tbody>\\n<tr><td>Amount                                </td><td>29935                                                                                                                                                                 </td><td>         </td><td>26099                                                                                                                                                              </td><td>          </td></tr>\\n<tr><td>AMOUNT_OF_LFS                         </td><td>4.7                                                                                                                                                                   </td><td>±2.74%   </td><td>4.8                                                                                                                                                                </td><td>±3.00%    </td></tr>\\n<tr><td>DATASET                               </td><td>synthetic: 15350 | cifar10: 1506 | flag: 1274 | australian: 1146 | DIABETES: 1065                                                                                     </td><td>         </td><td>synthetic: 3238,HEART: 1703,FERTILITY: 1686,PLANNING: 1339,abalone: 1331                                                                                           </td><td>          </td></tr>\\n<tr><td>FRACTION_OF_INITIALLY_LABELLED_SAMPLES</td><td>0.48                                                                                                                                                                  </td><td>±0.31%   </td><td>0.5                                                                                                                                                                </td><td>±0.35%    </td></tr>\\n<tr><td>FRACTION_OF_LASTLY_AL_LABELLED_SAMPLES</td><td>0.54                                                                                                                                                                  </td><td>±0.31%   </td><td>0.46                                                                                                                                                               </td><td>±0.36%    </td></tr>\\n<tr><td>MERGE_WS_SAMPLES_STRATEGY             </td><td>RandomLabelMergeStrategy: 11205 | MajorityVoteLabelMergeStrategy: 10264 | SnorkelLabelMergeStrategy: 8466                                                             </td><td>         </td><td>MajorityVoteLabelMergeStrategy: 10274,RandomLabelMergeStrategy: 9699,SnorkelLabelMergeStrategy: 6126                                                               </td><td>          </td></tr>\\n<tr><td>acc_al_and_al                         </td><td>0.6                                                                                                                                                                   </td><td>±0.20%   </td><td>0.56                                                                                                                                                               </td><td>±0.33%    </td></tr>\\n<tr><td>acc_al_and_ws_and_al                  </td><td>0.58                                                                                                                                                                  </td><td>±0.20%   </td><td>0.56                                                                                                                                                               </td><td>±0.31%    </td></tr>\\n<tr><td>acc_initial                           </td><td>0.58                                                                                                                                                                  </td><td>±0.20%   </td><td>0.58                                                                                                                                                               </td><td>±0.32%    </td></tr>\\n<tr><td>acc_ws                                </td><td>0.53                                                                                                                                                                  </td><td>±0.20%   </td><td>0.59                                                                                                                                                               </td><td>±0.31%    </td></tr>\\n<tr><td>al_sampling_strategy                  </td><td>Random: 5235 | CoveredByLeastAmountOfLf: 5132 | UncertaintyMaxMargin_no_ws: 5053 | UncertaintyMaxMargin_with_ws: 5053 | GreatestDisagreement: 4878                    </td><td>         </td><td>ClassificationIsMostWrong: 4755,GreatestDisagreement: 4461,UncertaintyMaxMargin_no_ws: 4286,UncertaintyMaxMargin_with_ws: 4286,CoveredByLeastAmountOfLf: 4207      </td><td>          </td></tr>\\n<tr><td>amount_of_initial_al_samples          </td><td>8.1e+02                                                                                                                                                               </td><td>±2496.96%</td><td>8.1e+02                                                                                                                                                            </td><td>±3381.45% </td></tr>\\n<tr><td>amount_of_lastly_al_samples           </td><td>4.2e+02                                                                                                                                                               </td><td>±1389.82%</td><td>4.1e+02                                                                                                                                                            </td><td>±2191.22% </td></tr>\\n<tr><td>class_sep                             </td><td>2.1629113779317177: 15350 | ?: 14585                                                                                                                                  </td><td>         </td><td>?: 22861,2.1629113779317177: 3238                                                                                                                                  </td><td>          </td></tr>\\n<tr><td>f1_al_and_al                          </td><td>0.55                                                                                                                                                                  </td><td>±0.21%   </td><td>0.54                                                                                                                                                               </td><td>±0.32%    </td></tr>\\n<tr><td>f1_al_and_ws_and_al                   </td><td>0.52                                                                                                                                                                  </td><td>±0.23%   </td><td>0.53                                                                                                                                                               </td><td>±0.33%    </td></tr>\\n<tr><td>f1_initial                            </td><td>0.53                                                                                                                                                                  </td><td>±0.22%   </td><td>0.56                                                                                                                                                               </td><td>±0.32%    </td></tr>\\n<tr><td>f1_ws                                 </td><td>0.47                                                                                                                                                                  </td><td>±0.23%   </td><td>0.55                                                                                                                                                               </td><td>±0.34%    </td></tr>\\n<tr><td>flip_y                                </td><td>0.014139337972832518: 15350 | ?: 14585                                                                                                                                </td><td>         </td><td>?: 22861,0.014139337972832518: 3238                                                                                                                                </td><td>          </td></tr>\\n<tr><td>hypercube                             </td><td>False: 15350 | ?: 14585                                                                                                                                               </td><td>         </td><td>?: 22861,False: 3238                                                                                                                                               </td><td>          </td></tr>\\n<tr><td>n_classes                             </td><td>6.2                                                                                                                                                                   </td><td>±5.19%   </td><td>6.2                                                                                                                                                                </td><td>±10.94%   </td></tr>\\n<tr><td>n_clusters_per_class                  </td><td>2: 15350 | ?: 14585                                                                                                                                                   </td><td>         </td><td>?: 22861,2: 3238                                                                                                                                                   </td><td>          </td></tr>\\n<tr><td>n_features                            </td><td>2.3e+02                                                                                                                                                               </td><td>±842.75% </td><td>2.4e+02                                                                                                                                                            </td><td>±1040.99% </td></tr>\\n<tr><td>n_informative                         </td><td>2.2e+02                                                                                                                                                               </td><td>±845.97% </td><td>2.3e+02                                                                                                                                                            </td><td>±1041.77% </td></tr>\\n<tr><td>n_redundant                           </td><td>8.7                                                                                                                                                                   </td><td>±9.63%   </td><td>2.1                                                                                                                                                                </td><td>±6.80%    </td></tr>\\n<tr><td>n_repeated                            </td><td>2.6                                                                                                                                                                   </td><td>±2.83%   </td><td>0.62                                                                                                                                                               </td><td>±2.00%    </td></tr>\\n<tr><td>n_samples                             </td><td>3.3e+03                                                                                                                                                               </td><td>±8600.81%</td><td>3.2e+03                                                                                                                                                            </td><td>±11712.35%</td></tr>\\n<tr><td>scale                                 </td><td>0.01: 15350 | ?: 14585                                                                                                                                                </td><td>         </td><td>?: 22861,0.01: 3238                                                                                                                                                </td><td>          </td></tr>\\n<tr><td>weights                               </td><td>[0.06775667270454466, 0.30890863849777156, 0.007983477918928901, 0.022832889838942067, 0.3774195345677848, 0.10398455550059044, 0.11111423097143755]: 15350 | ?: 14585</td><td>         </td><td>?: 22861,[0.06775667270454466, 0.30890863849777156, 0.007983477918928901, 0.022832889838942067, 0.3774195345677848, 0.10398455550059044, 0.11111423097143755]: 3238</td><td>          </td></tr>\\n<tr><td>ABSTAIN_THRESHOLDS_0.0                </td><td>0.23                                                                                                                                                                  </td><td>±0.55%   </td><td>0.24                                                                                                                                                               </td><td>±0.60%    </td></tr>\\n<tr><td>ABSTAIN_THRESHOLDS_0.9                </td><td>0.48                                                                                                                                                                  </td><td>±0.80%   </td><td>0.48                                                                                                                                                               </td><td>±0.85%    </td></tr>\\n<tr><td>ABSTAIN_THRESHOLDS_0.5                </td><td>0.47                                                                                                                                                                  </td><td>±0.78%   </td><td>0.47                                                                                                                                                               </td><td>±0.84%    </td></tr>\\n<tr><td>ABSTAIN_THRESHOLDS_0.4                </td><td>0.48                                                                                                                                                                  </td><td>±0.80%   </td><td>0.47                                                                                                                                                               </td><td>±0.85%    </td></tr>\\n<tr><td>ABSTAIN_THRESHOLDS_0.1                </td><td>0.46                                                                                                                                                                  </td><td>±0.78%   </td><td>0.48                                                                                                                                                               </td><td>±0.85%    </td></tr>\\n<tr><td>ABSTAIN_THRESHOLDS_0.2                </td><td>0.48                                                                                                                                                                  </td><td>±0.79%   </td><td>0.48                                                                                                                                                               </td><td>±0.86%    </td></tr>\\n<tr><td>ABSTAIN_THRESHOLDS_1.0                </td><td>0.24                                                                                                                                                                  </td><td>±0.55%   </td><td>0.25                                                                                                                                                               </td><td>±0.62%    </td></tr>\\n<tr><td>ABSTAIN_THRESHOLDS_0.7                </td><td>0.48                                                                                                                                                                  </td><td>±0.79%   </td><td>0.47                                                                                                                                                               </td><td>±0.84%    </td></tr>\\n<tr><td>ABSTAIN_THRESHOLDS_0.6                </td><td>0.47                                                                                                                                                                  </td><td>±0.79%   </td><td>0.48                                                                                                                                                               </td><td>±0.84%    </td></tr>\\n<tr><td>ABSTAIN_THRESHOLDS_0.3                </td><td>0.47                                                                                                                                                                  </td><td>±0.79%   </td><td>0.47                                                                                                                                                               </td><td>±0.85%    </td></tr>\\n<tr><td>ABSTAIN_THRESHOLDS_0.8                </td><td>0.46                                                                                                                                                                  </td><td>±0.78%   </td><td>0.47                                                                                                                                                               </td><td>±0.85%    </td></tr>\\n<tr><td>AL_SAMPLES_WEIGHT_30                  </td><td>0.092                                                                                                                                                                 </td><td>±0.33%   </td><td>0.091                                                                                                                                                              </td><td>±0.35%    </td></tr>\\n<tr><td>AL_SAMPLES_WEIGHT_10                  </td><td>0.086                                                                                                                                                                 </td><td>±0.32%   </td><td>0.081                                                                                                                                                              </td><td>±0.33%    </td></tr>\\n<tr><td>AL_SAMPLES_WEIGHT_50                  </td><td>0.092                                                                                                                                                                 </td><td>±0.33%   </td><td>0.089                                                                                                                                                              </td><td>±0.35%    </td></tr>\\n<tr><td>AL_SAMPLES_WEIGHT_40                  </td><td>0.11                                                                                                                                                                  </td><td>±0.36%   </td><td>0.11                                                                                                                                                               </td><td>±0.38%    </td></tr>\\n<tr><td>AL_SAMPLES_WEIGHT_70                  </td><td>0.09                                                                                                                                                                  </td><td>±0.32%   </td><td>0.088                                                                                                                                                              </td><td>±0.34%    </td></tr>\\n<tr><td>AL_SAMPLES_WEIGHT_0                   </td><td>0.056                                                                                                                                                                 </td><td>±0.26%   </td><td>0.057                                                                                                                                                              </td><td>±0.28%    </td></tr>\\n<tr><td>AL_SAMPLES_WEIGHT_80                  </td><td>0.11                                                                                                                                                                  </td><td>±0.36%   </td><td>0.11                                                                                                                                                               </td><td>±0.39%    </td></tr>\\n<tr><td>AL_SAMPLES_WEIGHT_90                  </td><td>0.084                                                                                                                                                                 </td><td>±0.31%   </td><td>0.092                                                                                                                                                              </td><td>±0.35%    </td></tr>\\n<tr><td>AL_SAMPLES_WEIGHT_60                  </td><td>0.11                                                                                                                                                                  </td><td>±0.35%   </td><td>0.11                                                                                                                                                               </td><td>±0.37%    </td></tr>\\n<tr><td>AL_SAMPLES_WEIGHT_100                 </td><td>0.052                                                                                                                                                                 </td><td>±0.25%   </td><td>0.05                                                                                                                                                               </td><td>±0.27%    </td></tr>\\n<tr><td>AL_SAMPLES_WEIGHT_20                  </td><td>0.12                                                                                                                                                                  </td><td>±0.36%   </td><td>0.12                                                                                                                                                               </td><td>±0.40%    </td></tr>\\n<tr><td>LF_CLASSIFIERS_knn                    </td><td>1.6                                                                                                                                                                   </td><td>±1.47%   </td><td>1.5                                                                                                                                                                </td><td>±1.61%    </td></tr>\\n<tr><td>LF_CLASSIFIERS_dt                     </td><td>1.6                                                                                                                                                                   </td><td>±1.47%   </td><td>1.6                                                                                                                                                                </td><td>±1.59%    </td></tr>\\n<tr><td>LF_CLASSIFIERS_lr                     </td><td>1.5                                                                                                                                                                   </td><td>±1.46%   </td><td>1.6                                                                                                                                                                </td><td>±1.61%    </td></tr>\\n<tr><td>AMOUNT_OF_LF_FEATURESSS_1             </td><td>2.9                                                                                                                                                                   </td><td>±2.07%   </td><td>2.9                                                                                                                                                                </td><td>±2.27%    </td></tr>\\n<tr><td>AMOUNT_OF_LF_FEATURESSS_2             </td><td>0.83                                                                                                                                                                  </td><td>±1.04%   </td><td>0.82                                                                                                                                                               </td><td>±1.13%    </td></tr>\\n<tr><td>AMOUNT_OF_LF_FEATURESSS_5             </td><td>0.24                                                                                                                                                                  </td><td>±0.57%   </td><td>0.25                                                                                                                                                               </td><td>±0.62%    </td></tr>\\n<tr><td>AMOUNT_OF_LF_FEATURESSS_3             </td><td>0.47                                                                                                                                                                  </td><td>±0.80%   </td><td>0.48                                                                                                                                                               </td><td>±0.86%    </td></tr>\\n<tr><td>AMOUNT_OF_LF_FEATURESSS_4             </td><td>0.33                                                                                                                                                                  </td><td>±0.66%   </td><td>0.32                                                                                                                                                               </td><td>±0.70%    </td></tr>\\n</tbody>\\n</table>'"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "def comparison_table(df, selection):\n",
    "    print(len(df))\n",
    "    filtered_df = df[selection]\n",
    "    not_filtered_df = df[~selection]\n",
    "    result = [[\"Amount\" ,len(filtered_df), \"\", len(not_filtered_df), \"\"]]\n",
    "    skip_keys = [\"DATASET_RANDOM_GENERATION_SEED\", \"LF_RANDOM_SEED\", \"random_state\", \"JOB_ID\", ]\n",
    "    for key in df.keys():\n",
    "        if key in skip_keys:\n",
    "            continue\n",
    "        if df.dtypes[key] == np.float64 or df.dtypes[key] == np.int64:\n",
    "            selection = filtered_df[key]\n",
    "            not_selection = not_filtered_df[key]\n",
    "            average = selection.mean()\n",
    "            not_average = not_selection.mean()\n",
    "            error_area = 1.96 * selection.std() / math.sqrt(selection.count())\n",
    "            not_error_area = (\n",
    "                1.96 * not_selection.std() / math.sqrt(not_selection.count())\n",
    "            )\n",
    "            result.append((key, \"{:4.2}\".format(average), \"±{:4.2%}\".format(error_area), \"{:4.2}\".format(not_average), \"±{:4.2%}\".format(not_error_area)))\n",
    "\n",
    "        elif df.dtypes[key] == object:\n",
    "            average = \" | \".join(\n",
    "                [\n",
    "                    k + \": \" + str(v)\n",
    "                    for k, v in filtered_df[key].value_counts().nlargest(5).iteritems()\n",
    "                ]\n",
    "            )\n",
    "            not_average = \",\".join(\n",
    "                [\n",
    "                    k + \": \" + str(v)\n",
    "                    for k, v in not_filtered_df[key]\n",
    "                    .value_counts()\n",
    "                    .nlargest(5)\n",
    "                    .iteritems()\n",
    "                ]\n",
    "            )\n",
    "            result.append((key, average, \"\", not_average, \"\"))\n",
    "        else:\n",
    "            print(key)\n",
    "            print(df.dtypes[key])\n",
    "\n",
    "    return result\n",
    "\n",
    "    \"\"\"\n",
    "    mean = selection.mean()\n",
    "    error_area = 1.96 * selection.std() / math.sqrt(\n",
    "            selection.count()\n",
    "        )\n",
    "    results.append([key, mean, error_area])\n",
    "    print(TITLE)\n",
    "    print(\"{:>60} {:>6} {:>4}\".format(\"\", \"Mean\", \"\"))\n",
    "    for result in results:\n",
    "        print(\"{:<50} {:>6.2%} ±{:>4.2%}\".format(result[0], float(result[1]), float(result[2])))\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "result = comparison_table(\n",
    "    df, df[\"acc_al_and_ws_and_al\"] > df[\"acc_ws\"] \n",
    ")\n",
    "print(\"Accuracy after AL, WS, AL is greater than after AL and WS\")\n",
    "tabulate(result, tablefmt='html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56034\n",
      "Accuracy after AL, WS, AL is greater than after AL and WS\n"
     ]
    },
    {
     "data": {
      "text/html": "<table>\n<tbody>\n<tr><td>Amount                                </td><td>18588                                                                                                                                                      </td><td>        </td><td>37446                                                                                                                                                        </td><td>          </td></tr>\n<tr><td>AMOUNT_OF_LFS                         </td><td>4.7                                                                                                                                                        </td><td>±3.44%  </td><td>4.8                                                                                                                                                          </td><td>±2.50%    </td></tr>\n<tr><td>DATASET                               </td><td>synthetic: 18588                                                                                                                                           </td><td>        </td><td>HABERMAN: 2028,australian: 1974,ILPD: 1914,dwtc: 1896,HEART: 1890                                                                                            </td><td>          </td></tr>\n<tr><td>FRACTION_OF_INITIALLY_LABELLED_SAMPLES</td><td>0.5                                                                                                                                                        </td><td>±0.41%  </td><td>0.48                                                                                                                                                         </td><td>±0.28%    </td></tr>\n<tr><td>FRACTION_OF_LASTLY_AL_LABELLED_SAMPLES</td><td>0.5                                                                                                                                                        </td><td>±0.41%  </td><td>0.51                                                                                                                                                         </td><td>±0.29%    </td></tr>\n<tr><td>MERGE_WS_SAMPLES_STRATEGY             </td><td>MajorityVoteLabelMergeStrategy: 6972 | RandomLabelMergeStrategy: 6606 | SnorkelLabelMergeStrategy: 5010                                                    </td><td>        </td><td>RandomLabelMergeStrategy: 14298,MajorityVoteLabelMergeStrategy: 13566,SnorkelLabelMergeStrategy: 9582                                                        </td><td>          </td></tr>\n<tr><td>acc_al_and_al                         </td><td>0.57                                                                                                                                                       </td><td>±0.06%  </td><td>0.59                                                                                                                                                         </td><td>±0.28%    </td></tr>\n<tr><td>acc_al_and_ws_and_al                  </td><td>0.53                                                                                                                                                       </td><td>±0.09%  </td><td>0.59                                                                                                                                                         </td><td>±0.27%    </td></tr>\n<tr><td>acc_initial                           </td><td>0.54                                                                                                                                                       </td><td>±0.09%  </td><td>0.6                                                                                                                                                          </td><td>±0.27%    </td></tr>\n<tr><td>acc_ws                                </td><td>0.49                                                                                                                                                       </td><td>±0.09%  </td><td>0.59                                                                                                                                                         </td><td>±0.26%    </td></tr>\n<tr><td>al_sampling_strategy                  </td><td>UncertaintyMaxMargin_no_ws: 3098 | ClassificationIsMostWrong: 3098 | CoveredByLeastAmountOfLf: 3098 | UncertaintyMaxMargin_with_ws: 3098 | Random: 3098    </td><td>        </td><td>UncertaintyMaxMargin_no_ws: 6241,CoveredByLeastAmountOfLf: 6241,UncertaintyMaxMargin_with_ws: 6241,GreatestDisagreement: 6241,ClassificationIsMostWrong: 6241</td><td>          </td></tr>\n<tr><td>amount_of_initial_al_samples          </td><td>6e+02                                                                                                                                                      </td><td>±489.89%</td><td>9.1e+02                                                                                                                                                      </td><td>±3073.49% </td></tr>\n<tr><td>amount_of_lastly_al_samples           </td><td>3e+02                                                                                                                                                      </td><td>±371.27%</td><td>4.8e+02                                                                                                                                                      </td><td>±1876.76% </td></tr>\n<tr><td>class_sep                             </td><td>2.1629113779317177: 18588                                                                                                                                  </td><td>        </td><td>?: 37446                                                                                                                                                     </td><td>          </td></tr>\n<tr><td>f1_al_and_al                          </td><td>0.48                                                                                                                                                       </td><td>±0.06%  </td><td>0.58                                                                                                                                                         </td><td>±0.28%    </td></tr>\n<tr><td>f1_al_and_ws_and_al                   </td><td>0.43                                                                                                                                                       </td><td>±0.11%  </td><td>0.57                                                                                                                                                         </td><td>±0.28%    </td></tr>\n<tr><td>f1_initial                            </td><td>0.46                                                                                                                                                       </td><td>±0.09%  </td><td>0.58                                                                                                                                                         </td><td>±0.27%    </td></tr>\n<tr><td>f1_ws                                 </td><td>0.39                                                                                                                                                       </td><td>±0.11%  </td><td>0.56                                                                                                                                                         </td><td>±0.28%    </td></tr>\n<tr><td>flip_y                                </td><td>0.014139337972832518: 18588                                                                                                                                </td><td>        </td><td>?: 37446                                                                                                                                                     </td><td>          </td></tr>\n<tr><td>hypercube                             </td><td>False: 18588                                                                                                                                               </td><td>        </td><td>?: 37446                                                                                                                                                     </td><td>          </td></tr>\n<tr><td>n_classes                             </td><td>7.0                                                                                                                                                        </td><td>±0.00%  </td><td>5.8                                                                                                                                                          </td><td>±8.65%    </td></tr>\n<tr><td>n_clusters_per_class                  </td><td>2: 18588                                                                                                                                                   </td><td>        </td><td>?: 37446                                                                                                                                                     </td><td>          </td></tr>\n<tr><td>n_features                            </td><td>5.4e+01                                                                                                                                                    </td><td>±0.00%  </td><td>3.2e+02                                                                                                                                                      </td><td>±977.86%  </td></tr>\n<tr><td>n_informative                         </td><td>3.1e+01                                                                                                                                                    </td><td>±0.00%  </td><td>3.2e+02                                                                                                                                                      </td><td>±977.86%  </td></tr>\n<tr><td>n_redundant                           </td><td>1.7e+01                                                                                                                                                    </td><td>±0.00%  </td><td>0.0                                                                                                                                                          </td><td>±0.00%    </td></tr>\n<tr><td>n_repeated                            </td><td>5.0                                                                                                                                                        </td><td>±0.00%  </td><td>0.0                                                                                                                                                          </td><td>±0.00%    </td></tr>\n<tr><td>n_samples                             </td><td>2.4e+03                                                                                                                                                    </td><td>±0.00%  </td><td>3.7e+03                                                                                                                                                      </td><td>±10646.87%</td></tr>\n<tr><td>scale                                 </td><td>0.01: 18588                                                                                                                                                </td><td>        </td><td>?: 37446                                                                                                                                                     </td><td>          </td></tr>\n<tr><td>weights                               </td><td>[0.06775667270454466, 0.30890863849777156, 0.007983477918928901, 0.022832889838942067, 0.3774195345677848, 0.10398455550059044, 0.11111423097143755]: 18588</td><td>        </td><td>?: 37446                                                                                                                                                     </td><td>          </td></tr>\n<tr><td>ABSTAIN_THRESHOLDS_0.0                </td><td>0.24                                                                                                                                                       </td><td>±0.71%  </td><td>0.23                                                                                                                                                         </td><td>±0.50%    </td></tr>\n<tr><td>ABSTAIN_THRESHOLDS_0.9                </td><td>0.47                                                                                                                                                       </td><td>±1.00%  </td><td>0.49                                                                                                                                                         </td><td>±0.71%    </td></tr>\n<tr><td>ABSTAIN_THRESHOLDS_0.5                </td><td>0.47                                                                                                                                                       </td><td>±0.97%  </td><td>0.48                                                                                                                                                         </td><td>±0.71%    </td></tr>\n<tr><td>ABSTAIN_THRESHOLDS_0.4                </td><td>0.48                                                                                                                                                       </td><td>±1.02%  </td><td>0.47                                                                                                                                                         </td><td>±0.71%    </td></tr>\n<tr><td>ABSTAIN_THRESHOLDS_0.1                </td><td>0.45                                                                                                                                                       </td><td>±0.98%  </td><td>0.48                                                                                                                                                         </td><td>±0.71%    </td></tr>\n<tr><td>ABSTAIN_THRESHOLDS_0.2                </td><td>0.48                                                                                                                                                       </td><td>±0.99%  </td><td>0.48                                                                                                                                                         </td><td>±0.72%    </td></tr>\n<tr><td>ABSTAIN_THRESHOLDS_1.0                </td><td>0.23                                                                                                                                                       </td><td>±0.70%  </td><td>0.25                                                                                                                                                         </td><td>±0.51%    </td></tr>\n<tr><td>ABSTAIN_THRESHOLDS_0.7                </td><td>0.47                                                                                                                                                       </td><td>±1.00%  </td><td>0.48                                                                                                                                                         </td><td>±0.71%    </td></tr>\n<tr><td>ABSTAIN_THRESHOLDS_0.6                </td><td>0.47                                                                                                                                                       </td><td>±0.98%  </td><td>0.47                                                                                                                                                         </td><td>±0.71%    </td></tr>\n<tr><td>ABSTAIN_THRESHOLDS_0.3                </td><td>0.47                                                                                                                                                       </td><td>±0.99%  </td><td>0.47                                                                                                                                                         </td><td>±0.72%    </td></tr>\n<tr><td>ABSTAIN_THRESHOLDS_0.8                </td><td>0.46                                                                                                                                                       </td><td>±0.99%  </td><td>0.48                                                                                                                                                         </td><td>±0.70%    </td></tr>\n<tr><td>AL_SAMPLES_WEIGHT_30                  </td><td>0.094                                                                                                                                                      </td><td>±0.42%  </td><td>0.09                                                                                                                                                         </td><td>±0.29%    </td></tr>\n<tr><td>AL_SAMPLES_WEIGHT_10                  </td><td>0.081                                                                                                                                                      </td><td>±0.39%  </td><td>0.085                                                                                                                                                        </td><td>±0.28%    </td></tr>\n<tr><td>AL_SAMPLES_WEIGHT_50                  </td><td>0.096                                                                                                                                                      </td><td>±0.42%  </td><td>0.088                                                                                                                                                        </td><td>±0.29%    </td></tr>\n<tr><td>AL_SAMPLES_WEIGHT_40                  </td><td>0.11                                                                                                                                                       </td><td>±0.46%  </td><td>0.11                                                                                                                                                         </td><td>±0.32%    </td></tr>\n<tr><td>AL_SAMPLES_WEIGHT_70                  </td><td>0.084                                                                                                                                                      </td><td>±0.40%  </td><td>0.092                                                                                                                                                        </td><td>±0.29%    </td></tr>\n<tr><td>AL_SAMPLES_WEIGHT_0                   </td><td>0.056                                                                                                                                                      </td><td>±0.33%  </td><td>0.056                                                                                                                                                        </td><td>±0.23%    </td></tr>\n<tr><td>AL_SAMPLES_WEIGHT_80                  </td><td>0.1                                                                                                                                                        </td><td>±0.43%  </td><td>0.12                                                                                                                                                         </td><td>±0.33%    </td></tr>\n<tr><td>AL_SAMPLES_WEIGHT_90                  </td><td>0.091                                                                                                                                                      </td><td>±0.41%  </td><td>0.087                                                                                                                                                        </td><td>±0.28%    </td></tr>\n<tr><td>AL_SAMPLES_WEIGHT_60                  </td><td>0.11                                                                                                                                                       </td><td>±0.45%  </td><td>0.1                                                                                                                                                          </td><td>±0.31%    </td></tr>\n<tr><td>AL_SAMPLES_WEIGHT_100                 </td><td>0.053                                                                                                                                                      </td><td>±0.32%  </td><td>0.05                                                                                                                                                         </td><td>±0.22%    </td></tr>\n<tr><td>AL_SAMPLES_WEIGHT_20                  </td><td>0.12                                                                                                                                                       </td><td>±0.47%  </td><td>0.12                                                                                                                                                         </td><td>±0.33%    </td></tr>\n<tr><td>LF_CLASSIFIERS_knn                    </td><td>1.6                                                                                                                                                        </td><td>±1.88%  </td><td>1.6                                                                                                                                                          </td><td>±1.33%    </td></tr>\n<tr><td>LF_CLASSIFIERS_dt                     </td><td>1.6                                                                                                                                                        </td><td>±1.85%  </td><td>1.6                                                                                                                                                          </td><td>±1.33%    </td></tr>\n<tr><td>LF_CLASSIFIERS_lr                     </td><td>1.5                                                                                                                                                        </td><td>±1.83%  </td><td>1.6                                                                                                                                                          </td><td>±1.34%    </td></tr>\n<tr><td>AMOUNT_OF_LF_FEATURESSS_1             </td><td>2.8                                                                                                                                                        </td><td>±2.58%  </td><td>2.9                                                                                                                                                          </td><td>±1.89%    </td></tr>\n<tr><td>AMOUNT_OF_LF_FEATURESSS_2             </td><td>0.82                                                                                                                                                       </td><td>±1.29%  </td><td>0.83                                                                                                                                                         </td><td>±0.95%    </td></tr>\n<tr><td>AMOUNT_OF_LF_FEATURESSS_5             </td><td>0.28                                                                                                                                                       </td><td>±0.76%  </td><td>0.23                                                                                                                                                         </td><td>±0.50%    </td></tr>\n<tr><td>AMOUNT_OF_LF_FEATURESSS_3             </td><td>0.48                                                                                                                                                       </td><td>±1.01%  </td><td>0.47                                                                                                                                                         </td><td>±0.72%    </td></tr>\n<tr><td>AMOUNT_OF_LF_FEATURESSS_4             </td><td>0.33                                                                                                                                                       </td><td>±0.86%  </td><td>0.32                                                                                                                                                         </td><td>±0.58%    </td></tr>\n</tbody>\n</table>",
      "text/plain": "'<table>\\n<tbody>\\n<tr><td>Amount                                </td><td>18588                                                                                                                                                      </td><td>        </td><td>37446                                                                                                                                                        </td><td>          </td></tr>\\n<tr><td>AMOUNT_OF_LFS                         </td><td>4.7                                                                                                                                                        </td><td>±3.44%  </td><td>4.8                                                                                                                                                          </td><td>±2.50%    </td></tr>\\n<tr><td>DATASET                               </td><td>synthetic: 18588                                                                                                                                           </td><td>        </td><td>HABERMAN: 2028,australian: 1974,ILPD: 1914,dwtc: 1896,HEART: 1890                                                                                            </td><td>          </td></tr>\\n<tr><td>FRACTION_OF_INITIALLY_LABELLED_SAMPLES</td><td>0.5                                                                                                                                                        </td><td>±0.41%  </td><td>0.48                                                                                                                                                         </td><td>±0.28%    </td></tr>\\n<tr><td>FRACTION_OF_LASTLY_AL_LABELLED_SAMPLES</td><td>0.5                                                                                                                                                        </td><td>±0.41%  </td><td>0.51                                                                                                                                                         </td><td>±0.29%    </td></tr>\\n<tr><td>MERGE_WS_SAMPLES_STRATEGY             </td><td>MajorityVoteLabelMergeStrategy: 6972 | RandomLabelMergeStrategy: 6606 | SnorkelLabelMergeStrategy: 5010                                                    </td><td>        </td><td>RandomLabelMergeStrategy: 14298,MajorityVoteLabelMergeStrategy: 13566,SnorkelLabelMergeStrategy: 9582                                                        </td><td>          </td></tr>\\n<tr><td>acc_al_and_al                         </td><td>0.57                                                                                                                                                       </td><td>±0.06%  </td><td>0.59                                                                                                                                                         </td><td>±0.28%    </td></tr>\\n<tr><td>acc_al_and_ws_and_al                  </td><td>0.53                                                                                                                                                       </td><td>±0.09%  </td><td>0.59                                                                                                                                                         </td><td>±0.27%    </td></tr>\\n<tr><td>acc_initial                           </td><td>0.54                                                                                                                                                       </td><td>±0.09%  </td><td>0.6                                                                                                                                                          </td><td>±0.27%    </td></tr>\\n<tr><td>acc_ws                                </td><td>0.49                                                                                                                                                       </td><td>±0.09%  </td><td>0.59                                                                                                                                                         </td><td>±0.26%    </td></tr>\\n<tr><td>al_sampling_strategy                  </td><td>UncertaintyMaxMargin_no_ws: 3098 | ClassificationIsMostWrong: 3098 | CoveredByLeastAmountOfLf: 3098 | UncertaintyMaxMargin_with_ws: 3098 | Random: 3098    </td><td>        </td><td>UncertaintyMaxMargin_no_ws: 6241,CoveredByLeastAmountOfLf: 6241,UncertaintyMaxMargin_with_ws: 6241,GreatestDisagreement: 6241,ClassificationIsMostWrong: 6241</td><td>          </td></tr>\\n<tr><td>amount_of_initial_al_samples          </td><td>6e+02                                                                                                                                                      </td><td>±489.89%</td><td>9.1e+02                                                                                                                                                      </td><td>±3073.49% </td></tr>\\n<tr><td>amount_of_lastly_al_samples           </td><td>3e+02                                                                                                                                                      </td><td>±371.27%</td><td>4.8e+02                                                                                                                                                      </td><td>±1876.76% </td></tr>\\n<tr><td>class_sep                             </td><td>2.1629113779317177: 18588                                                                                                                                  </td><td>        </td><td>?: 37446                                                                                                                                                     </td><td>          </td></tr>\\n<tr><td>f1_al_and_al                          </td><td>0.48                                                                                                                                                       </td><td>±0.06%  </td><td>0.58                                                                                                                                                         </td><td>±0.28%    </td></tr>\\n<tr><td>f1_al_and_ws_and_al                   </td><td>0.43                                                                                                                                                       </td><td>±0.11%  </td><td>0.57                                                                                                                                                         </td><td>±0.28%    </td></tr>\\n<tr><td>f1_initial                            </td><td>0.46                                                                                                                                                       </td><td>±0.09%  </td><td>0.58                                                                                                                                                         </td><td>±0.27%    </td></tr>\\n<tr><td>f1_ws                                 </td><td>0.39                                                                                                                                                       </td><td>±0.11%  </td><td>0.56                                                                                                                                                         </td><td>±0.28%    </td></tr>\\n<tr><td>flip_y                                </td><td>0.014139337972832518: 18588                                                                                                                                </td><td>        </td><td>?: 37446                                                                                                                                                     </td><td>          </td></tr>\\n<tr><td>hypercube                             </td><td>False: 18588                                                                                                                                               </td><td>        </td><td>?: 37446                                                                                                                                                     </td><td>          </td></tr>\\n<tr><td>n_classes                             </td><td>7.0                                                                                                                                                        </td><td>±0.00%  </td><td>5.8                                                                                                                                                          </td><td>±8.65%    </td></tr>\\n<tr><td>n_clusters_per_class                  </td><td>2: 18588                                                                                                                                                   </td><td>        </td><td>?: 37446                                                                                                                                                     </td><td>          </td></tr>\\n<tr><td>n_features                            </td><td>5.4e+01                                                                                                                                                    </td><td>±0.00%  </td><td>3.2e+02                                                                                                                                                      </td><td>±977.86%  </td></tr>\\n<tr><td>n_informative                         </td><td>3.1e+01                                                                                                                                                    </td><td>±0.00%  </td><td>3.2e+02                                                                                                                                                      </td><td>±977.86%  </td></tr>\\n<tr><td>n_redundant                           </td><td>1.7e+01                                                                                                                                                    </td><td>±0.00%  </td><td>0.0                                                                                                                                                          </td><td>±0.00%    </td></tr>\\n<tr><td>n_repeated                            </td><td>5.0                                                                                                                                                        </td><td>±0.00%  </td><td>0.0                                                                                                                                                          </td><td>±0.00%    </td></tr>\\n<tr><td>n_samples                             </td><td>2.4e+03                                                                                                                                                    </td><td>±0.00%  </td><td>3.7e+03                                                                                                                                                      </td><td>±10646.87%</td></tr>\\n<tr><td>scale                                 </td><td>0.01: 18588                                                                                                                                                </td><td>        </td><td>?: 37446                                                                                                                                                     </td><td>          </td></tr>\\n<tr><td>weights                               </td><td>[0.06775667270454466, 0.30890863849777156, 0.007983477918928901, 0.022832889838942067, 0.3774195345677848, 0.10398455550059044, 0.11111423097143755]: 18588</td><td>        </td><td>?: 37446                                                                                                                                                     </td><td>          </td></tr>\\n<tr><td>ABSTAIN_THRESHOLDS_0.0                </td><td>0.24                                                                                                                                                       </td><td>±0.71%  </td><td>0.23                                                                                                                                                         </td><td>±0.50%    </td></tr>\\n<tr><td>ABSTAIN_THRESHOLDS_0.9                </td><td>0.47                                                                                                                                                       </td><td>±1.00%  </td><td>0.49                                                                                                                                                         </td><td>±0.71%    </td></tr>\\n<tr><td>ABSTAIN_THRESHOLDS_0.5                </td><td>0.47                                                                                                                                                       </td><td>±0.97%  </td><td>0.48                                                                                                                                                         </td><td>±0.71%    </td></tr>\\n<tr><td>ABSTAIN_THRESHOLDS_0.4                </td><td>0.48                                                                                                                                                       </td><td>±1.02%  </td><td>0.47                                                                                                                                                         </td><td>±0.71%    </td></tr>\\n<tr><td>ABSTAIN_THRESHOLDS_0.1                </td><td>0.45                                                                                                                                                       </td><td>±0.98%  </td><td>0.48                                                                                                                                                         </td><td>±0.71%    </td></tr>\\n<tr><td>ABSTAIN_THRESHOLDS_0.2                </td><td>0.48                                                                                                                                                       </td><td>±0.99%  </td><td>0.48                                                                                                                                                         </td><td>±0.72%    </td></tr>\\n<tr><td>ABSTAIN_THRESHOLDS_1.0                </td><td>0.23                                                                                                                                                       </td><td>±0.70%  </td><td>0.25                                                                                                                                                         </td><td>±0.51%    </td></tr>\\n<tr><td>ABSTAIN_THRESHOLDS_0.7                </td><td>0.47                                                                                                                                                       </td><td>±1.00%  </td><td>0.48                                                                                                                                                         </td><td>±0.71%    </td></tr>\\n<tr><td>ABSTAIN_THRESHOLDS_0.6                </td><td>0.47                                                                                                                                                       </td><td>±0.98%  </td><td>0.47                                                                                                                                                         </td><td>±0.71%    </td></tr>\\n<tr><td>ABSTAIN_THRESHOLDS_0.3                </td><td>0.47                                                                                                                                                       </td><td>±0.99%  </td><td>0.47                                                                                                                                                         </td><td>±0.72%    </td></tr>\\n<tr><td>ABSTAIN_THRESHOLDS_0.8                </td><td>0.46                                                                                                                                                       </td><td>±0.99%  </td><td>0.48                                                                                                                                                         </td><td>±0.70%    </td></tr>\\n<tr><td>AL_SAMPLES_WEIGHT_30                  </td><td>0.094                                                                                                                                                      </td><td>±0.42%  </td><td>0.09                                                                                                                                                         </td><td>±0.29%    </td></tr>\\n<tr><td>AL_SAMPLES_WEIGHT_10                  </td><td>0.081                                                                                                                                                      </td><td>±0.39%  </td><td>0.085                                                                                                                                                        </td><td>±0.28%    </td></tr>\\n<tr><td>AL_SAMPLES_WEIGHT_50                  </td><td>0.096                                                                                                                                                      </td><td>±0.42%  </td><td>0.088                                                                                                                                                        </td><td>±0.29%    </td></tr>\\n<tr><td>AL_SAMPLES_WEIGHT_40                  </td><td>0.11                                                                                                                                                       </td><td>±0.46%  </td><td>0.11                                                                                                                                                         </td><td>±0.32%    </td></tr>\\n<tr><td>AL_SAMPLES_WEIGHT_70                  </td><td>0.084                                                                                                                                                      </td><td>±0.40%  </td><td>0.092                                                                                                                                                        </td><td>±0.29%    </td></tr>\\n<tr><td>AL_SAMPLES_WEIGHT_0                   </td><td>0.056                                                                                                                                                      </td><td>±0.33%  </td><td>0.056                                                                                                                                                        </td><td>±0.23%    </td></tr>\\n<tr><td>AL_SAMPLES_WEIGHT_80                  </td><td>0.1                                                                                                                                                        </td><td>±0.43%  </td><td>0.12                                                                                                                                                         </td><td>±0.33%    </td></tr>\\n<tr><td>AL_SAMPLES_WEIGHT_90                  </td><td>0.091                                                                                                                                                      </td><td>±0.41%  </td><td>0.087                                                                                                                                                        </td><td>±0.28%    </td></tr>\\n<tr><td>AL_SAMPLES_WEIGHT_60                  </td><td>0.11                                                                                                                                                       </td><td>±0.45%  </td><td>0.1                                                                                                                                                          </td><td>±0.31%    </td></tr>\\n<tr><td>AL_SAMPLES_WEIGHT_100                 </td><td>0.053                                                                                                                                                      </td><td>±0.32%  </td><td>0.05                                                                                                                                                         </td><td>±0.22%    </td></tr>\\n<tr><td>AL_SAMPLES_WEIGHT_20                  </td><td>0.12                                                                                                                                                       </td><td>±0.47%  </td><td>0.12                                                                                                                                                         </td><td>±0.33%    </td></tr>\\n<tr><td>LF_CLASSIFIERS_knn                    </td><td>1.6                                                                                                                                                        </td><td>±1.88%  </td><td>1.6                                                                                                                                                          </td><td>±1.33%    </td></tr>\\n<tr><td>LF_CLASSIFIERS_dt                     </td><td>1.6                                                                                                                                                        </td><td>±1.85%  </td><td>1.6                                                                                                                                                          </td><td>±1.33%    </td></tr>\\n<tr><td>LF_CLASSIFIERS_lr                     </td><td>1.5                                                                                                                                                        </td><td>±1.83%  </td><td>1.6                                                                                                                                                          </td><td>±1.34%    </td></tr>\\n<tr><td>AMOUNT_OF_LF_FEATURESSS_1             </td><td>2.8                                                                                                                                                        </td><td>±2.58%  </td><td>2.9                                                                                                                                                          </td><td>±1.89%    </td></tr>\\n<tr><td>AMOUNT_OF_LF_FEATURESSS_2             </td><td>0.82                                                                                                                                                       </td><td>±1.29%  </td><td>0.83                                                                                                                                                         </td><td>±0.95%    </td></tr>\\n<tr><td>AMOUNT_OF_LF_FEATURESSS_5             </td><td>0.28                                                                                                                                                       </td><td>±0.76%  </td><td>0.23                                                                                                                                                         </td><td>±0.50%    </td></tr>\\n<tr><td>AMOUNT_OF_LF_FEATURESSS_3             </td><td>0.48                                                                                                                                                       </td><td>±1.01%  </td><td>0.47                                                                                                                                                         </td><td>±0.72%    </td></tr>\\n<tr><td>AMOUNT_OF_LF_FEATURESSS_4             </td><td>0.33                                                                                                                                                       </td><td>±0.86%  </td><td>0.32                                                                                                                                                         </td><td>±0.58%    </td></tr>\\n</tbody>\\n</table>'"
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = comparison_table(\n",
    "    df, (df[\"n_repeated\"] > 4 )&(df[\"n_redundant\"] >8)\n",
    ")\n",
    "print(\"Accuracy after AL, WS, AL is greater than after AL and WS\")\n",
    "tabulate(result, tablefmt='html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:>"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['n_redundant'].hist()\n",
    "df['n_repeated'].hist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('code': pipenv)",
   "name": "python3810jvsc74a57bd0178c561f06d1c9b562d26393e106d1bb838dc5f57458805df561d13c135e6443"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}