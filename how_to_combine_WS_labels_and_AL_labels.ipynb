{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from active_learning.learner.standard import Learner, get_classifier\n",
    "from active_learning.weak_supervision.SelfTraining import SelfTraining\n",
    "import argparse\n",
    "import numpy as np\n",
    "import copy\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from timeit import default_timer as timer\n",
    "from typing import List\n",
    "from active_learning.config import get_active_config\n",
    "from active_learning.dataStorage import DataStorage\n",
    "from active_learning.datasets import load_synthetic\n",
    "from active_learning.logger import init_logger\n",
    "from active_learning.merge_weak_supervision_label_strategies.MajorityVoteLabelMergeStrategy import (\n",
    "    MajorityVoteLabelMergeStrategy,\n",
    ")\n",
    "from collections import Counter\n",
    "\n",
    "from active_learning.weak_supervision import SyntheticLabelingFunctions\n",
    "from active_learning.weak_supervision.BaseWeakSupervision import BaseWeakSupervision\n",
    "\n",
    "config = argparse.Namespace()\n",
    "config.AMOUNT_OF_FEATURES = 1\n",
    "config.RANDOM_SEED = 0\n",
    "config.AMOUNT_OF_SYNTHETIC_LABELLING_FUNCTIONS = 20\n",
    "config.OUTPUT_PATH = \"tmp\"\n",
    "config.LOG_FILE = \"tmp.log\"\n",
    "config.TEST_FRACTION = 0.5\n",
    "\n",
    "# -2 means that a true random seed is used, all other numbers use the provided CLI argument random_seed\n",
    "if config.RANDOM_SEED == -2:\n",
    "    random_but_not_random = True\n",
    "else:\n",
    "    random_but_not_random = False\n",
    "\n",
    "\n",
    "init_logger(config.LOG_FILE)\n",
    "\n",
    "if random_but_not_random:\n",
    "    config.RANDOM_SEED = random.randint(0, 2147483647)\n",
    "    np.random.seed(config.RANDOM_SEED)\n",
    "    random.seed(config.RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_print_prediction(Y_pred, Y_true, title):\n",
    "    acc = accuracy_score(Y_true, Y_pred)\n",
    "    f1 = f1_score(Y_true, Y_pred, average=\"weighted\")\n",
    "    c = Counter(Y_pred)\n",
    "\n",
    "    return [\n",
    "        title,\n",
    "        acc,\n",
    "        f1,\n",
    "        c.most_common(1)[0][0],\n",
    "        c.most_common(1)[0][1] / len(Y_pred),\n",
    "    ]\n",
    "\n",
    "\n",
    "def train_and_evaluate(title, original_data_storage, WEIGHTS=0, WS=True):\n",
    "    data_storage = copy.deepcopy(original_data_storage)\n",
    "    learner = get_classifier(\"RF\", random_state=config.RANDOM_SEED)\n",
    "    data_storage.generate_weak_labels(learner)\n",
    "\n",
    "    if WEIGHTS != 0:\n",
    "        weights = []\n",
    "        for indice in data_storage.weakly_combined_mask:\n",
    "            if indice in data_storage.labeled_mask:\n",
    "                weights.append(WEIGHTS)\n",
    "            else:\n",
    "                weights.append(1)\n",
    "    else:\n",
    "        weights = None\n",
    "    if WS:\n",
    "        mask = data_storage.weakly_combined_mask\n",
    "    else:\n",
    "        mask = data_storage.labeled_mask\n",
    "\n",
    "    learner.fit(\n",
    "        data_storage.X[mask],\n",
    "        data_storage.Y_merged_final[mask],\n",
    "        sample_weight=weights,  # type: ignore\n",
    "    )\n",
    "    Y_pred = learner.predict(data_storage.X[data_storage.test_mask])\n",
    "\n",
    "    Y_true = data_storage.exp_Y[data_storage.test_mask]\n",
    "\n",
    "    return evaluate_and_print_prediction(Y_pred, Y_true, title)\n",
    "\n",
    "\n",
    "def test_one_labeled_set(original_data_storage, label_strategy=\"random\", param=5):\n",
    "    data_storage = copy.deepcopy(original_data_storage)\n",
    "\n",
    "    if label_strategy == \"random\":\n",
    "        random_sample_ids = np.random.choice(\n",
    "            data_storage.unlabeled_mask,\n",
    "            size=param,\n",
    "            replace=False,\n",
    "        )\n",
    "\n",
    "        data_storage.label_samples(\n",
    "            random_sample_ids, data_storage.exp_Y[random_sample_ids], \"AL\"\n",
    "        )\n",
    "\n",
    "    return [\n",
    "        train_and_evaluate(\"RF No WS\", data_storage, WS=False)\n",
    "        + [label_strategy, param],\n",
    "        train_and_evaluate(\"RF No Weights\", data_storage) + [label_strategy, param],\n",
    "        train_and_evaluate(\"RF Weights 10\", data_storage, WEIGHTS=10)\n",
    "        + [label_strategy, param],\n",
    "        train_and_evaluate(\"RF Weights 50\", data_storage, WEIGHTS=50)\n",
    "        + [label_strategy, param],\n",
    "        train_and_evaluate(\"RF Weights 100\", data_storage, WEIGHTS=100)\n",
    "        + [label_strategy, param],\n",
    "        train_and_evaluate(\"RF Weights 1000\", data_storage, WEIGHTS=1000)\n",
    "        + [label_strategy, param],\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem: many WS labels conceal even the best AL labels (which are in contrast waaaaay less)\n",
    "\n",
    "# LF When applied individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>Acc</th>\n      <th>F1</th>\n      <th>MC</th>\n      <th>MC%</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>L_lr #3: [3, 11, 7]</td>\n      <td>0.305944</td>\n      <td>0.344939</td>\n      <td>2</td>\n      <td>0.36014</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>L_lr #1: [4]</td>\n      <td>0.358392</td>\n      <td>0.526503</td>\n      <td>2</td>\n      <td>0.36014</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>L_dt #3: [8, 0, 14]</td>\n      <td>0.473776</td>\n      <td>0.491909</td>\n      <td>2</td>\n      <td>0.36014</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>L_dt #7: [16, 9, 10, 6, 12, 18, 1]</td>\n      <td>0.604895</td>\n      <td>0.616009</td>\n      <td>2</td>\n      <td>0.36014</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>L_lr #7: [14, 1, 6, 5, 7, 16, 18]</td>\n      <td>0.400350</td>\n      <td>0.423170</td>\n      <td>2</td>\n      <td>0.36014</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>L_knn #3: [9, 7, 13]</td>\n      <td>0.442308</td>\n      <td>0.447483</td>\n      <td>2</td>\n      <td>0.36014</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>L_knn #6: [5, 6, 13, 2, 16, 20]</td>\n      <td>0.365385</td>\n      <td>0.335110</td>\n      <td>2</td>\n      <td>0.36014</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>L_lr #4: [18, 16, 17, 14]</td>\n      <td>0.300699</td>\n      <td>0.336522</td>\n      <td>2</td>\n      <td>0.36014</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>L_dt #4: [3, 1, 4, 5]</td>\n      <td>0.482517</td>\n      <td>0.474695</td>\n      <td>2</td>\n      <td>0.36014</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>L_dt #4: [13, 2, 19, 9]</td>\n      <td>0.482517</td>\n      <td>0.474695</td>\n      <td>2</td>\n      <td>0.36014</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>L_dt #1: [9]</td>\n      <td>0.272727</td>\n      <td>0.295201</td>\n      <td>2</td>\n      <td>0.36014</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>L_dt #3: [16, 7, 9]</td>\n      <td>0.473776</td>\n      <td>0.491909</td>\n      <td>2</td>\n      <td>0.36014</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>L_knn #8: [7, 13, 16, 20, 14, 0, 5, 4]</td>\n      <td>0.540210</td>\n      <td>0.545052</td>\n      <td>2</td>\n      <td>0.36014</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>L_knn #10: [11, 9, 3, 12, 0, 17, 15, 2, 5, 1]</td>\n      <td>0.538462</td>\n      <td>0.546686</td>\n      <td>2</td>\n      <td>0.36014</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>L_lr #3: [19, 16, 0]</td>\n      <td>0.384615</td>\n      <td>0.434410</td>\n      <td>2</td>\n      <td>0.36014</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>L_dt #10: [19, 18, 11, 17, 5, 16, 4, 13, 12, 15]</td>\n      <td>0.648601</td>\n      <td>0.648668</td>\n      <td>2</td>\n      <td>0.36014</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>L_lr #3: [12, 5, 0]</td>\n      <td>0.328671</td>\n      <td>0.403842</td>\n      <td>2</td>\n      <td>0.36014</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>L_lr #1: [2]</td>\n      <td>0.236014</td>\n      <td>0.298389</td>\n      <td>2</td>\n      <td>0.36014</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>L_knn #10: [0, 11, 17, 18, 19, 9, 4, 7, 8, 1]</td>\n      <td>0.559441</td>\n      <td>0.575841</td>\n      <td>2</td>\n      <td>0.36014</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>L_lr #2: [10, 8]</td>\n      <td>0.444056</td>\n      <td>0.535986</td>\n      <td>2</td>\n      <td>0.36014</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                               title       Acc        F1  MC  \\\n0                                L_lr #3: [3, 11, 7]  0.305944  0.344939   2   \n1                                       L_lr #1: [4]  0.358392  0.526503   2   \n2                                L_dt #3: [8, 0, 14]  0.473776  0.491909   2   \n3                 L_dt #7: [16, 9, 10, 6, 12, 18, 1]  0.604895  0.616009   2   \n4                  L_lr #7: [14, 1, 6, 5, 7, 16, 18]  0.400350  0.423170   2   \n5                               L_knn #3: [9, 7, 13]  0.442308  0.447483   2   \n6                    L_knn #6: [5, 6, 13, 2, 16, 20]  0.365385  0.335110   2   \n7                          L_lr #4: [18, 16, 17, 14]  0.300699  0.336522   2   \n8                              L_dt #4: [3, 1, 4, 5]  0.482517  0.474695   2   \n9                            L_dt #4: [13, 2, 19, 9]  0.482517  0.474695   2   \n10                                      L_dt #1: [9]  0.272727  0.295201   2   \n11                               L_dt #3: [16, 7, 9]  0.473776  0.491909   2   \n12            L_knn #8: [7, 13, 16, 20, 14, 0, 5, 4]  0.540210  0.545052   2   \n13     L_knn #10: [11, 9, 3, 12, 0, 17, 15, 2, 5, 1]  0.538462  0.546686   2   \n14                              L_lr #3: [19, 16, 0]  0.384615  0.434410   2   \n15  L_dt #10: [19, 18, 11, 17, 5, 16, 4, 13, 12, 15]  0.648601  0.648668   2   \n16                               L_lr #3: [12, 5, 0]  0.328671  0.403842   2   \n17                                      L_lr #1: [2]  0.236014  0.298389   2   \n18     L_knn #10: [0, 11, 17, 18, 19, 9, 4, 7, 8, 1]  0.559441  0.575841   2   \n19                                  L_lr #2: [10, 8]  0.444056  0.535986   2   \n\n        MC%  \n0   0.36014  \n1   0.36014  \n2   0.36014  \n3   0.36014  \n4   0.36014  \n5   0.36014  \n6   0.36014  \n7   0.36014  \n8   0.36014  \n9   0.36014  \n10  0.36014  \n11  0.36014  \n12  0.36014  \n13  0.36014  \n14  0.36014  \n15  0.36014  \n16  0.36014  \n17  0.36014  \n18  0.36014  \n19  0.36014  "
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df, synthetic_creation_args = load_synthetic(\n",
    "    config.RANDOM_SEED,\n",
    ")\n",
    "\n",
    "data_storage: DataStorage = DataStorage(df=df, TEST_FRACTION=config.TEST_FRACTION)\n",
    "learner = get_classifier(\"RF\", random_state=config.RANDOM_SEED)\n",
    "\n",
    "learner.fit(\n",
    "    data_storage.X[data_storage.labeled_mask],\n",
    "    data_storage.Y_merged_final[data_storage.labeled_mask],\n",
    ")\n",
    "\n",
    "\n",
    "ws_list: List[BaseWeakSupervision] = [\n",
    "    SyntheticLabelingFunctions(X=data_storage.X, Y=data_storage.exp_Y)\n",
    "    for _ in range(0, config.AMOUNT_OF_SYNTHETIC_LABELLING_FUNCTIONS)\n",
    "]  # type: ignore\n",
    "\n",
    "\n",
    "# tweak to do more than one iteration of self training!\n",
    "\"\"\" ws_list.append(SelfTraining(0.99, 0.99))\n",
    "ws_list.append(SelfTraining(0.9, 0.9))\n",
    "ws_list.append(SelfTraining(0.8, 0.8))\n",
    "ws_list.append(SelfTraining(0.7, 0.7)) \"\"\"\n",
    "\n",
    "# add label propagation\n",
    "\n",
    "\"\"\"print(data_storage.test_mask)\n",
    "print(data_storage.unlabeled_mask)\n",
    "print(data_storage.labeled_mask)\n",
    "print(len(data_storage.X))\n",
    "\"\"\"\n",
    "\n",
    "results = []\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "for ws in ws_list:\n",
    "    # calculate f1 and acc for ws on test AND train dataset\n",
    "    # it actually only get's computed on the test mask, not the train mask itself\n",
    "    Y_pred = ws.get_labels(data_storage.test_mask, data_storage, learner)\n",
    "\n",
    "    results.append(\n",
    "        evaluate_and_print_prediction(\n",
    "            data_storage.exp_Y[data_storage.test_mask], Y_pred, ws.identifier\n",
    "        )\n",
    "    )\n",
    "\n",
    "pd.DataFrame(results, columns=[\"title\", \"Acc\", \"F1\", \"MC\", \"MC%\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine all LFs with Majority Vote, no classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>Acc</th>\n      <th>F1</th>\n      <th>MC</th>\n      <th>MC%</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Majority Vote</td>\n      <td>0.527972</td>\n      <td>0.501197</td>\n      <td>2.0</td>\n      <td>0.473776</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "           title       Acc        F1   MC       MC%\n0  Majority Vote  0.527972  0.501197  2.0  0.473776"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_storage.set_weak_supervisions(ws_list, MajorityVoteLabelMergeStrategy())\n",
    "data_storage.generate_weak_labels(learner, mask=data_storage.test_mask)\n",
    "\n",
    "# Only Majority Vote, no classifier\n",
    "results = [\n",
    "    evaluate_and_print_prediction(\n",
    "        data_storage.Y_merged_final[data_storage.test_mask],\n",
    "        data_storage.exp_Y[data_storage.test_mask],\n",
    "        \"Majority Vote\",\n",
    "    )\n",
    "]\n",
    "pd.DataFrame(results, columns=[\"title\", \"Acc\", \"F1\", \"MC\", \"MC%\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LFs with majority Vote + some random samples (potentially from AL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "exit(-1)\n",
    "test_one_labeled_set(data_storage, label_strategy=\"random\", param=5)\n",
    "exit(-1)\n",
    "test_one_labeled_set(data_storage, label_strategy=\"random\", param=10)\n",
    "test_one_labeled_set(data_storage, label_strategy=\"random\", param=25)\n",
    "test_one_labeled_set(data_storage, label_strategy=\"random\", param=50)\n",
    "test_one_labeled_set(data_storage, label_strategy=\"random\", param=100)\n",
    "test_one_labeled_set(data_storage, label_strategy=\"random\", param=200)\n",
    "'''\n",
    "\n",
    "result:List = test_one_labeled_set(data_storage, label_strategy=\"start_set\", param=0)\n",
    "result += test_one_labeled_set(data_storage, label_strategy=\"random\", param=5)\n",
    "test_one_labeled_set(data_storage, label_strategy=\"random\", param=10)\n",
    "test_one_labeled_set(data_storage, label_strategy=\"random\", param=25)\n",
    "test_one_labeled_set(data_storage, label_strategy=\"random\", param=50)\n",
    "test_one_labeled_set(data_storage, label_strategy=\"random\", param=100)\n",
    "test_one_labeled_set(data_storage, label_strategy=\"random\", param=200)\n",
    "random_df = pd.DataFrame(result, columns=[\"title\", \"Acc\", \"F1\", \"MC\", \"MC%\", \"label_strategy\", \"#randomly labeled\"])\n",
    "random_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -> how to combine AL and WS labels in a way, that the experiment actually benefits from the labels\n",
    "\n",
    "# compute the 50/100/200/500 worst wrongly classified samples -> classify them correctly (aka. fake active learning) -> is there really room for improvement after falsely applyed WS??\n",
    "\n",
    "# use potentially good samples instead of random ones\n",
    "\n",
    "\n",
    "# wrong_mask = np.logical_not(np.array_equal(Y_pred, Y_true))\n",
    "\n",
    "# print(data_storage.Y_merged_final[wrong_mask])\n",
    "# print(data_storage.exp_Y[wrong_mask])\n",
    "\n",
    "# calculate acc/f1 now and before ONLY on those without abstain!, but add \"coverage\" to the WS LF\n",
    "# a) get those samples, who are least covered by the LF\n",
    "# b) get those samples, where the classification is wrong by the merged LFs\n",
    "# c) get those samples, with the greatest disagreement among the LFs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('code-oYwF_TsS': venv)",
   "name": "python3613jvsc74a57bd0178c561f06d1c9b562d26393e106d1bb838dc5f57458805df561d13c135e6443"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}