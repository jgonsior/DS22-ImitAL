{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from active_learning.learner.standard import Learner, get_classifier\n",
    "from active_learning.weak_supervision.SelfTraining import SelfTraining\n",
    "import argparse\n",
    "import numpy as np\n",
    "import copy\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from timeit import default_timer as timer\n",
    "from typing import List\n",
    "from active_learning.config import get_active_config\n",
    "from active_learning.dataStorage import DataStorage\n",
    "from active_learning.datasets import load_synthetic\n",
    "from active_learning.logger import init_logger\n",
    "from active_learning.merge_weak_supervision_label_strategies.MajorityVoteLabelMergeStrategy import (\n",
    "    MajorityVoteLabelMergeStrategy,\n",
    ")\n",
    "from collections import Counter\n",
    "\n",
    "from active_learning.weak_supervision import SyntheticLabelingFunctions\n",
    "from active_learning.weak_supervision.BaseWeakSupervision import BaseWeakSupervision\n",
    "\n",
    "config = argparse.Namespace()\n",
    "config.AMOUNT_OF_FEATURES = 1\n",
    "config.RANDOM_SEED = 0\n",
    "config.AMOUNT_OF_SYNTHETIC_LABELLING_FUNCTIONS = 20\n",
    "config.OUTPUT_PATH = \"tmp\"\n",
    "config.LOG_FILE = \"tmp.log\"\n",
    "config.TEST_FRACTION = 0.5\n",
    "\n",
    "# -2 means that a true random seed is used, all other numbers use the provided CLI argument random_seed\n",
    "if config.RANDOM_SEED == -2:\n",
    "    random_but_not_random = True\n",
    "else:\n",
    "    random_but_not_random = False\n",
    "\n",
    "\n",
    "init_logger(config.LOG_FILE)\n",
    "\n",
    "if random_but_not_random:\n",
    "    config.RANDOM_SEED = random.randint(0, 2147483647)\n",
    "    np.random.seed(config.RANDOM_SEED)\n",
    "    random.seed(config.RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_print_prediction(Y_pred, Y_true, title):\n",
    "    acc = accuracy_score(Y_true, Y_pred)\n",
    "    f1 = f1_score(Y_true, Y_pred, average=\"weighted\")\n",
    "    c = Counter(Y_pred)\n",
    "\n",
    "    return [\n",
    "        title,\n",
    "        acc,\n",
    "        f1,\n",
    "        c.most_common(1)[0][0],\n",
    "        c.most_common(1)[0][1] / len(Y_pred),\n",
    "    ]\n",
    "\n",
    "\n",
    "def train_and_evaluate(title, original_data_storage, WEIGHTS=0, WS=True):\n",
    "    data_storage = copy.deepcopy(original_data_storage)\n",
    "    learner = get_classifier(\"RF\", random_state=config.RANDOM_SEED)\n",
    "    data_storage.generate_weak_labels(learner)\n",
    "\n",
    "    if WEIGHTS != 0:\n",
    "        weights = []\n",
    "        for indice in data_storage.weakly_combined_mask:\n",
    "            if indice in data_storage.labeled_mask:\n",
    "                weights.append(WEIGHTS)\n",
    "            else:\n",
    "                weights.append(1)\n",
    "    else:\n",
    "        weights = None\n",
    "    if WS:\n",
    "        mask = data_storage.weakly_combined_mask\n",
    "    else:\n",
    "        mask = data_storage.labeled_mask\n",
    "\n",
    "    learner.fit(\n",
    "        data_storage.X[mask],\n",
    "        data_storage.Y_merged_final[mask],\n",
    "        sample_weight=weights,  # type: ignore\n",
    "    )\n",
    "    Y_pred = learner.predict(data_storage.X[data_storage.test_mask])\n",
    "\n",
    "    Y_true = data_storage.exp_Y[data_storage.test_mask]\n",
    "\n",
    "    return evaluate_and_print_prediction(Y_pred, Y_true, title)\n",
    "\n",
    "\n",
    "def test_one_labeled_set(original_data_storage, label_strategy=\"random\", param=5):\n",
    "    data_storage = copy.deepcopy(original_data_storage)\n",
    "\n",
    "    if label_strategy == \"random\":\n",
    "        random_sample_ids = np.random.choice(\n",
    "            data_storage.unlabeled_mask,\n",
    "            size=param,\n",
    "            replace=False,\n",
    "        )\n",
    "\n",
    "        data_storage.label_samples(\n",
    "            random_sample_ids, data_storage.exp_Y[random_sample_ids], \"AL\"\n",
    "        )\n",
    "\n",
    "    return [\n",
    "        train_and_evaluate(\"RF No WS\", data_storage, WS=False)\n",
    "        + [label_strategy, param],\n",
    "        train_and_evaluate(\"RF No Weights\", data_storage) + [label_strategy, param],\n",
    "        train_and_evaluate(\"RF Weights 10\", data_storage, WEIGHTS=10)\n",
    "        + [label_strategy, param],\n",
    "        train_and_evaluate(\"RF Weights 50\", data_storage, WEIGHTS=50)\n",
    "        + [label_strategy, param],\n",
    "        train_and_evaluate(\"RF Weights 100\", data_storage, WEIGHTS=100)\n",
    "        + [label_strategy, param],\n",
    "        train_and_evaluate(\"RF Weights 1000\", data_storage, WEIGHTS=1000)\n",
    "        + [label_strategy, param],\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem: many WS labels conceal even the best AL labels (which are in contrast waaaaay less)\n",
    "\n",
    "# LF When applied individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>Acc</th>\n      <th>F1</th>\n      <th>MC</th>\n      <th>MC%</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>L_lr #3: [3, 11, 7]</td>\n      <td>0.305944</td>\n      <td>0.344939</td>\n      <td>2</td>\n      <td>0.36014</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>L_lr #1: [4]</td>\n      <td>0.358392</td>\n      <td>0.526503</td>\n      <td>2</td>\n      <td>0.36014</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>L_dt #3: [8, 0, 14]</td>\n      <td>0.473776</td>\n      <td>0.491909</td>\n      <td>2</td>\n      <td>0.36014</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>L_dt #7: [16, 9, 10, 6, 12, 18, 1]</td>\n      <td>0.604895</td>\n      <td>0.616009</td>\n      <td>2</td>\n      <td>0.36014</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>L_lr #7: [14, 1, 6, 5, 7, 16, 18]</td>\n      <td>0.400350</td>\n      <td>0.423170</td>\n      <td>2</td>\n      <td>0.36014</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>L_knn #3: [9, 7, 13]</td>\n      <td>0.442308</td>\n      <td>0.447483</td>\n      <td>2</td>\n      <td>0.36014</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>L_knn #6: [5, 6, 13, 2, 16, 20]</td>\n      <td>0.365385</td>\n      <td>0.335110</td>\n      <td>2</td>\n      <td>0.36014</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>L_lr #4: [18, 16, 17, 14]</td>\n      <td>0.300699</td>\n      <td>0.336522</td>\n      <td>2</td>\n      <td>0.36014</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>L_dt #4: [3, 1, 4, 5]</td>\n      <td>0.482517</td>\n      <td>0.474695</td>\n      <td>2</td>\n      <td>0.36014</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>L_dt #4: [13, 2, 19, 9]</td>\n      <td>0.482517</td>\n      <td>0.474695</td>\n      <td>2</td>\n      <td>0.36014</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>L_dt #1: [9]</td>\n      <td>0.272727</td>\n      <td>0.295201</td>\n      <td>2</td>\n      <td>0.36014</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>L_dt #3: [16, 7, 9]</td>\n      <td>0.473776</td>\n      <td>0.491909</td>\n      <td>2</td>\n      <td>0.36014</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>L_knn #8: [7, 13, 16, 20, 14, 0, 5, 4]</td>\n      <td>0.540210</td>\n      <td>0.545052</td>\n      <td>2</td>\n      <td>0.36014</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>L_knn #10: [11, 9, 3, 12, 0, 17, 15, 2, 5, 1]</td>\n      <td>0.538462</td>\n      <td>0.546686</td>\n      <td>2</td>\n      <td>0.36014</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>L_lr #3: [19, 16, 0]</td>\n      <td>0.384615</td>\n      <td>0.434410</td>\n      <td>2</td>\n      <td>0.36014</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>L_dt #10: [19, 18, 11, 17, 5, 16, 4, 13, 12, 15]</td>\n      <td>0.648601</td>\n      <td>0.648668</td>\n      <td>2</td>\n      <td>0.36014</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>L_lr #3: [12, 5, 0]</td>\n      <td>0.328671</td>\n      <td>0.403842</td>\n      <td>2</td>\n      <td>0.36014</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>L_lr #1: [2]</td>\n      <td>0.236014</td>\n      <td>0.298389</td>\n      <td>2</td>\n      <td>0.36014</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>L_knn #10: [0, 11, 17, 18, 19, 9, 4, 7, 8, 1]</td>\n      <td>0.559441</td>\n      <td>0.575841</td>\n      <td>2</td>\n      <td>0.36014</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>L_lr #2: [10, 8]</td>\n      <td>0.444056</td>\n      <td>0.535986</td>\n      <td>2</td>\n      <td>0.36014</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                               title       Acc        F1  MC  \\\n0                                L_lr #3: [3, 11, 7]  0.305944  0.344939   2   \n1                                       L_lr #1: [4]  0.358392  0.526503   2   \n2                                L_dt #3: [8, 0, 14]  0.473776  0.491909   2   \n3                 L_dt #7: [16, 9, 10, 6, 12, 18, 1]  0.604895  0.616009   2   \n4                  L_lr #7: [14, 1, 6, 5, 7, 16, 18]  0.400350  0.423170   2   \n5                               L_knn #3: [9, 7, 13]  0.442308  0.447483   2   \n6                    L_knn #6: [5, 6, 13, 2, 16, 20]  0.365385  0.335110   2   \n7                          L_lr #4: [18, 16, 17, 14]  0.300699  0.336522   2   \n8                              L_dt #4: [3, 1, 4, 5]  0.482517  0.474695   2   \n9                            L_dt #4: [13, 2, 19, 9]  0.482517  0.474695   2   \n10                                      L_dt #1: [9]  0.272727  0.295201   2   \n11                               L_dt #3: [16, 7, 9]  0.473776  0.491909   2   \n12            L_knn #8: [7, 13, 16, 20, 14, 0, 5, 4]  0.540210  0.545052   2   \n13     L_knn #10: [11, 9, 3, 12, 0, 17, 15, 2, 5, 1]  0.538462  0.546686   2   \n14                              L_lr #3: [19, 16, 0]  0.384615  0.434410   2   \n15  L_dt #10: [19, 18, 11, 17, 5, 16, 4, 13, 12, 15]  0.648601  0.648668   2   \n16                               L_lr #3: [12, 5, 0]  0.328671  0.403842   2   \n17                                      L_lr #1: [2]  0.236014  0.298389   2   \n18     L_knn #10: [0, 11, 17, 18, 19, 9, 4, 7, 8, 1]  0.559441  0.575841   2   \n19                                  L_lr #2: [10, 8]  0.444056  0.535986   2   \n\n        MC%  \n0   0.36014  \n1   0.36014  \n2   0.36014  \n3   0.36014  \n4   0.36014  \n5   0.36014  \n6   0.36014  \n7   0.36014  \n8   0.36014  \n9   0.36014  \n10  0.36014  \n11  0.36014  \n12  0.36014  \n13  0.36014  \n14  0.36014  \n15  0.36014  \n16  0.36014  \n17  0.36014  \n18  0.36014  \n19  0.36014  "
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df, synthetic_creation_args = load_synthetic(\n",
    "    config.RANDOM_SEED,\n",
    ")\n",
    "\n",
    "data_storage: DataStorage = DataStorage(df=df, TEST_FRACTION=config.TEST_FRACTION)\n",
    "learner = get_classifier(\"RF\", random_state=config.RANDOM_SEED)\n",
    "\n",
    "learner.fit(\n",
    "    data_storage.X[data_storage.labeled_mask],\n",
    "    data_storage.Y_merged_final[data_storage.labeled_mask],\n",
    ")\n",
    "\n",
    "\n",
    "ws_list: List[BaseWeakSupervision] = [\n",
    "    SyntheticLabelingFunctions(X=data_storage.X, Y=data_storage.exp_Y)\n",
    "    for _ in range(0, config.AMOUNT_OF_SYNTHETIC_LABELLING_FUNCTIONS)\n",
    "]  # type: ignore\n",
    "\n",
    "\n",
    "# tweak to do more than one iteration of self training!\n",
    "\"\"\" ws_list.append(SelfTraining(0.99, 0.99))\n",
    "ws_list.append(SelfTraining(0.9, 0.9))\n",
    "ws_list.append(SelfTraining(0.8, 0.8))\n",
    "ws_list.append(SelfTraining(0.7, 0.7)) \"\"\"\n",
    "\n",
    "# add label propagation\n",
    "\n",
    "\"\"\"print(data_storage.test_mask)\n",
    "print(data_storage.unlabeled_mask)\n",
    "print(data_storage.labeled_mask)\n",
    "print(len(data_storage.X))\n",
    "\"\"\"\n",
    "\n",
    "results = []\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "for ws in ws_list:\n",
    "    # calculate f1 and acc for ws on test AND train dataset\n",
    "    # it actually only get's computed on the test mask, not the train mask itself\n",
    "    Y_pred = ws.get_labels(data_storage.test_mask, data_storage, learner)\n",
    "\n",
    "    results.append(\n",
    "        evaluate_and_print_prediction(\n",
    "            data_storage.exp_Y[data_storage.test_mask], Y_pred, ws.identifier\n",
    "        )\n",
    "    )\n",
    "\n",
    "pd.DataFrame(results, columns=[\"title\", \"Acc\", \"F1\", \"MC\", \"MC%\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine all LFs with Majority Vote, no classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>Acc</th>\n      <th>F1</th>\n      <th>MC</th>\n      <th>MC%</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Majority Vote</td>\n      <td>0.527972</td>\n      <td>0.501197</td>\n      <td>2.0</td>\n      <td>0.473776</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "           title       Acc        F1   MC       MC%\n0  Majority Vote  0.527972  0.501197  2.0  0.473776"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_storage.set_weak_supervisions(ws_list, MajorityVoteLabelMergeStrategy())\n",
    "data_storage.generate_weak_labels(learner, mask=data_storage.test_mask)\n",
    "\n",
    "# Only Majority Vote, no classifier\n",
    "results = [\n",
    "    evaluate_and_print_prediction(\n",
    "        data_storage.Y_merged_final[data_storage.test_mask],\n",
    "        data_storage.exp_Y[data_storage.test_mask],\n",
    "        \"Majority Vote\",\n",
    "    )\n",
    "]\n",
    "pd.DataFrame(results, columns=[\"title\", \"Acc\", \"F1\", \"MC\", \"MC%\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LFs with majority Vote + some random samples (potentially from AL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>Acc</th>\n      <th>F1</th>\n      <th>MC</th>\n      <th>MC%</th>\n      <th>label_strategy</th>\n      <th>#randomly labeled</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>RF No WS</td>\n      <td>0.381119</td>\n      <td>0.347308</td>\n      <td>2.0</td>\n      <td>0.393357</td>\n      <td>start_set</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>RF No Weights</td>\n      <td>0.524476</td>\n      <td>0.388447</td>\n      <td>2.0</td>\n      <td>0.660839</td>\n      <td>start_set</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>RF Weights 10</td>\n      <td>0.527972</td>\n      <td>0.391012</td>\n      <td>2.0</td>\n      <td>0.667832</td>\n      <td>start_set</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>RF Weights 50</td>\n      <td>0.522727</td>\n      <td>0.387193</td>\n      <td>2.0</td>\n      <td>0.659091</td>\n      <td>start_set</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>RF Weights 100</td>\n      <td>0.522727</td>\n      <td>0.384606</td>\n      <td>2.0</td>\n      <td>0.662587</td>\n      <td>start_set</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>RF Weights 1000</td>\n      <td>0.527972</td>\n      <td>0.388585</td>\n      <td>2.0</td>\n      <td>0.669580</td>\n      <td>start_set</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>RF No WS</td>\n      <td>0.423077</td>\n      <td>0.401088</td>\n      <td>1.0</td>\n      <td>0.618881</td>\n      <td>random</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>RF No Weights</td>\n      <td>0.529720</td>\n      <td>0.394700</td>\n      <td>2.0</td>\n      <td>0.662587</td>\n      <td>random</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>RF Weights 10</td>\n      <td>0.529720</td>\n      <td>0.392077</td>\n      <td>2.0</td>\n      <td>0.669580</td>\n      <td>random</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>RF Weights 50</td>\n      <td>0.524476</td>\n      <td>0.388189</td>\n      <td>2.0</td>\n      <td>0.667832</td>\n      <td>random</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>RF Weights 100</td>\n      <td>0.526224</td>\n      <td>0.389551</td>\n      <td>2.0</td>\n      <td>0.664336</td>\n      <td>random</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>RF Weights 1000</td>\n      <td>0.529720</td>\n      <td>0.392330</td>\n      <td>2.0</td>\n      <td>0.662587</td>\n      <td>random</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>RF No WS</td>\n      <td>0.302448</td>\n      <td>0.268586</td>\n      <td>1.0</td>\n      <td>0.763986</td>\n      <td>random</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>RF No Weights</td>\n      <td>0.527972</td>\n      <td>0.391054</td>\n      <td>2.0</td>\n      <td>0.659091</td>\n      <td>random</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>RF Weights 10</td>\n      <td>0.526224</td>\n      <td>0.387173</td>\n      <td>2.0</td>\n      <td>0.669580</td>\n      <td>random</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>RF Weights 50</td>\n      <td>0.538462</td>\n      <td>0.399084</td>\n      <td>2.0</td>\n      <td>0.659091</td>\n      <td>random</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>RF Weights 100</td>\n      <td>0.540210</td>\n      <td>0.400320</td>\n      <td>2.0</td>\n      <td>0.659091</td>\n      <td>random</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>RF Weights 1000</td>\n      <td>0.540210</td>\n      <td>0.397797</td>\n      <td>2.0</td>\n      <td>0.657343</td>\n      <td>random</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>RF No WS</td>\n      <td>0.620629</td>\n      <td>0.603128</td>\n      <td>2.0</td>\n      <td>0.403846</td>\n      <td>random</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>RF No Weights</td>\n      <td>0.552448</td>\n      <td>0.442176</td>\n      <td>2.0</td>\n      <td>0.639860</td>\n      <td>random</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>RF Weights 10</td>\n      <td>0.559441</td>\n      <td>0.456677</td>\n      <td>2.0</td>\n      <td>0.624126</td>\n      <td>random</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>RF Weights 50</td>\n      <td>0.543706</td>\n      <td>0.425851</td>\n      <td>2.0</td>\n      <td>0.604895</td>\n      <td>random</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>RF Weights 100</td>\n      <td>0.547203</td>\n      <td>0.430711</td>\n      <td>2.0</td>\n      <td>0.604895</td>\n      <td>random</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>RF Weights 1000</td>\n      <td>0.547203</td>\n      <td>0.426240</td>\n      <td>2.0</td>\n      <td>0.603147</td>\n      <td>random</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>RF No WS</td>\n      <td>0.680070</td>\n      <td>0.661647</td>\n      <td>2.0</td>\n      <td>0.431818</td>\n      <td>random</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>RF No Weights</td>\n      <td>0.627622</td>\n      <td>0.574100</td>\n      <td>2.0</td>\n      <td>0.561189</td>\n      <td>random</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>RF Weights 10</td>\n      <td>0.603147</td>\n      <td>0.530710</td>\n      <td>2.0</td>\n      <td>0.592657</td>\n      <td>random</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>RF Weights 50</td>\n      <td>0.587413</td>\n      <td>0.505546</td>\n      <td>2.0</td>\n      <td>0.604895</td>\n      <td>random</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>RF Weights 100</td>\n      <td>0.587413</td>\n      <td>0.501269</td>\n      <td>2.0</td>\n      <td>0.604895</td>\n      <td>random</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>RF Weights 1000</td>\n      <td>0.585664</td>\n      <td>0.496561</td>\n      <td>2.0</td>\n      <td>0.606643</td>\n      <td>random</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>RF No WS</td>\n      <td>0.692308</td>\n      <td>0.679370</td>\n      <td>2.0</td>\n      <td>0.405594</td>\n      <td>random</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>RF No Weights</td>\n      <td>0.666084</td>\n      <td>0.619844</td>\n      <td>2.0</td>\n      <td>0.522727</td>\n      <td>random</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>RF Weights 10</td>\n      <td>0.667832</td>\n      <td>0.622348</td>\n      <td>2.0</td>\n      <td>0.520979</td>\n      <td>random</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>RF Weights 50</td>\n      <td>0.666084</td>\n      <td>0.616296</td>\n      <td>2.0</td>\n      <td>0.533217</td>\n      <td>random</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>RF Weights 100</td>\n      <td>0.666084</td>\n      <td>0.617628</td>\n      <td>2.0</td>\n      <td>0.522727</td>\n      <td>random</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>RF Weights 1000</td>\n      <td>0.667832</td>\n      <td>0.618991</td>\n      <td>2.0</td>\n      <td>0.527972</td>\n      <td>random</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>RF No WS</td>\n      <td>0.723776</td>\n      <td>0.704531</td>\n      <td>2.0</td>\n      <td>0.442308</td>\n      <td>random</td>\n      <td>200</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>RF No Weights</td>\n      <td>0.697552</td>\n      <td>0.662957</td>\n      <td>2.0</td>\n      <td>0.510490</td>\n      <td>random</td>\n      <td>200</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>RF Weights 10</td>\n      <td>0.694056</td>\n      <td>0.653197</td>\n      <td>2.0</td>\n      <td>0.505245</td>\n      <td>random</td>\n      <td>200</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>RF Weights 50</td>\n      <td>0.683566</td>\n      <td>0.640561</td>\n      <td>2.0</td>\n      <td>0.506993</td>\n      <td>random</td>\n      <td>200</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>RF Weights 100</td>\n      <td>0.680070</td>\n      <td>0.636894</td>\n      <td>2.0</td>\n      <td>0.508741</td>\n      <td>random</td>\n      <td>200</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>RF Weights 1000</td>\n      <td>0.688811</td>\n      <td>0.646131</td>\n      <td>2.0</td>\n      <td>0.508741</td>\n      <td>random</td>\n      <td>200</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "              title       Acc        F1   MC       MC% label_strategy  \\\n0          RF No WS  0.381119  0.347308  2.0  0.393357      start_set   \n1     RF No Weights  0.524476  0.388447  2.0  0.660839      start_set   \n2     RF Weights 10  0.527972  0.391012  2.0  0.667832      start_set   \n3     RF Weights 50  0.522727  0.387193  2.0  0.659091      start_set   \n4    RF Weights 100  0.522727  0.384606  2.0  0.662587      start_set   \n5   RF Weights 1000  0.527972  0.388585  2.0  0.669580      start_set   \n6          RF No WS  0.423077  0.401088  1.0  0.618881         random   \n7     RF No Weights  0.529720  0.394700  2.0  0.662587         random   \n8     RF Weights 10  0.529720  0.392077  2.0  0.669580         random   \n9     RF Weights 50  0.524476  0.388189  2.0  0.667832         random   \n10   RF Weights 100  0.526224  0.389551  2.0  0.664336         random   \n11  RF Weights 1000  0.529720  0.392330  2.0  0.662587         random   \n12         RF No WS  0.302448  0.268586  1.0  0.763986         random   \n13    RF No Weights  0.527972  0.391054  2.0  0.659091         random   \n14    RF Weights 10  0.526224  0.387173  2.0  0.669580         random   \n15    RF Weights 50  0.538462  0.399084  2.0  0.659091         random   \n16   RF Weights 100  0.540210  0.400320  2.0  0.659091         random   \n17  RF Weights 1000  0.540210  0.397797  2.0  0.657343         random   \n18         RF No WS  0.620629  0.603128  2.0  0.403846         random   \n19    RF No Weights  0.552448  0.442176  2.0  0.639860         random   \n20    RF Weights 10  0.559441  0.456677  2.0  0.624126         random   \n21    RF Weights 50  0.543706  0.425851  2.0  0.604895         random   \n22   RF Weights 100  0.547203  0.430711  2.0  0.604895         random   \n23  RF Weights 1000  0.547203  0.426240  2.0  0.603147         random   \n24         RF No WS  0.680070  0.661647  2.0  0.431818         random   \n25    RF No Weights  0.627622  0.574100  2.0  0.561189         random   \n26    RF Weights 10  0.603147  0.530710  2.0  0.592657         random   \n27    RF Weights 50  0.587413  0.505546  2.0  0.604895         random   \n28   RF Weights 100  0.587413  0.501269  2.0  0.604895         random   \n29  RF Weights 1000  0.585664  0.496561  2.0  0.606643         random   \n30         RF No WS  0.692308  0.679370  2.0  0.405594         random   \n31    RF No Weights  0.666084  0.619844  2.0  0.522727         random   \n32    RF Weights 10  0.667832  0.622348  2.0  0.520979         random   \n33    RF Weights 50  0.666084  0.616296  2.0  0.533217         random   \n34   RF Weights 100  0.666084  0.617628  2.0  0.522727         random   \n35  RF Weights 1000  0.667832  0.618991  2.0  0.527972         random   \n36         RF No WS  0.723776  0.704531  2.0  0.442308         random   \n37    RF No Weights  0.697552  0.662957  2.0  0.510490         random   \n38    RF Weights 10  0.694056  0.653197  2.0  0.505245         random   \n39    RF Weights 50  0.683566  0.640561  2.0  0.506993         random   \n40   RF Weights 100  0.680070  0.636894  2.0  0.508741         random   \n41  RF Weights 1000  0.688811  0.646131  2.0  0.508741         random   \n\n    #randomly labeled  \n0                   0  \n1                   0  \n2                   0  \n3                   0  \n4                   0  \n5                   0  \n6                   5  \n7                   5  \n8                   5  \n9                   5  \n10                  5  \n11                  5  \n12                 10  \n13                 10  \n14                 10  \n15                 10  \n16                 10  \n17                 10  \n18                 25  \n19                 25  \n20                 25  \n21                 25  \n22                 25  \n23                 25  \n24                 50  \n25                 50  \n26                 50  \n27                 50  \n28                 50  \n29                 50  \n30                100  \n31                100  \n32                100  \n33                100  \n34                100  \n35                100  \n36                200  \n37                200  \n38                200  \n39                200  \n40                200  \n41                200  "
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "exit(-1)\n",
    "test_one_labeled_set(data_storage, label_strategy=\"random\", param=5)\n",
    "exit(-1)\n",
    "test_one_labeled_set(data_storage, label_strategy=\"random\", param=10)\n",
    "test_one_labeled_set(data_storage, label_strategy=\"random\", param=25)\n",
    "test_one_labeled_set(data_storage, label_strategy=\"random\", param=50)\n",
    "test_one_labeled_set(data_storage, label_strategy=\"random\", param=100)\n",
    "test_one_labeled_set(data_storage, label_strategy=\"random\", param=200)\n",
    "'''\n",
    "\n",
    "result:List = test_one_labeled_set(data_storage, label_strategy=\"start_set\", param=0)\n",
    "result += test_one_labeled_set(data_storage, label_strategy=\"random\", param=5)\n",
    "result += test_one_labeled_set(data_storage, label_strategy=\"random\", param=10)\n",
    "result += test_one_labeled_set(data_storage, label_strategy=\"random\", param=25)\n",
    "result += test_one_labeled_set(data_storage, label_strategy=\"random\", param=50)\n",
    "result += test_one_labeled_set(data_storage, label_strategy=\"random\", param=100)\n",
    "result += test_one_labeled_set(data_storage, label_strategy=\"random\", param=200)\n",
    "random_df = pd.DataFrame(result, columns=[\"title\", \"Acc\", \"F1\", \"MC\", \"MC%\", \"label_strategy\", \"#randomly labeled\"])\n",
    "random_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -> how to combine AL and WS labels in a way, that the experiment actually benefits from the labels\n",
    "# try out different WS labeling strategies\n",
    "# 1. use potentially good samples based on Max-Margin instead of random ones\n",
    "# 2. compute the 50/100/200/500 worst wrongly classified samples -> classify them correctly (aka. fake active learning) -> is there really room for improvement after falsely applyed WS??\n",
    "\n",
    "\n",
    "# wrong_mask = np.logical_not(np.array_equal(Y_pred, Y_true))\n",
    "\n",
    "# print(data_storage.Y_merged_final[wrong_mask])\n",
    "# print(data_storage.exp_Y[wrong_mask])\n",
    "\n",
    "# calculate acc/f1 now and before ONLY on those without abstain!, but add \"coverage\" to the WS LF\n",
    "# a) get those samples, who are least covered by the LF\n",
    "# b) get those samples, where the classification is wrong by the merged LFs\n",
    "# c) get those samples, with the greatest disagreement among the LFs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('code-oYwF_TsS': venv)",
   "name": "python3613jvsc74a57bd0178c561f06d1c9b562d26393e106d1bb838dc5f57458805df561d13c135e6443"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}